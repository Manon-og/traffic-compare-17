export default {
  experiment_name: "final_defense_training_350ep",
  config: {
    learning_rate: 0.0005,
    epsilon_decay: 0.9995,
    memory_size: 50000,
    batch_size: 64,
    gamma: 0.98,
    sequence_length: 10,
    episodes: 350,
    target_update_freq: 10,
    save_freq: 25,
    validation_freq: 15,
    episode_duration: 300,
    warmup_time: 30,
    min_phase_time: 12,
    max_phase_time: 120,
    random_seed: 42,
    validation_episodes: 10,
    agent_type: "lstm",
    offline_episodes: 244,
    online_episodes: 106,
  },
  training_time_minutes: 627.9444489041964,
  best_reward: -209.18564883516726,
  convergence_episode: 300,
  training_results: [
    {
      episode: 1,
      scenario: "Day 20250812, Cycle 1",
      reward: -359.14791799937365,
      steps: 300,
      time_minutes: 1.1973313570022583,
      avg_loss: 0.15195967484328707,
      epsilon: 0.8886698277259029,
      vehicles: 355,
      completed_trips: 507,
      passenger_throughput: 8296.363636363638,
      memory_size: 300,
    },
    {
      episode: 2,
      scenario: "Day 20250717, Cycle 1",
      reward: -350.39090884221775,
      steps: 300,
      time_minutes: 1.3524713555971781,
      avg_loss: 0.07961647083361943,
      epsilon: 0.764856516910148,
      vehicles: 365,
      completed_trips: 494,
      passenger_throughput: 8083.636363636364,
      memory_size: 600,
    },
    {
      episode: 3,
      scenario: "Day 20250703, Cycle 2",
      reward: -313.7791988744754,
      steps: 300,
      time_minutes: 1.4220571597417195,
      avg_loss: 0.0923473346605897,
      epsilon: 0.658293410227447,
      vehicles: 372,
      completed_trips: 526,
      passenger_throughput: 8607.272727272728,
      memory_size: 900,
    },
    {
      episode: 4,
      scenario: "Day 20250717, Cycle 2",
      reward: -347.6032400996689,
      steps: 300,
      time_minutes: 1.4369152307510376,
      avg_loss: 0.11264018359283606,
      epsilon: 0.5665771348847519,
      vehicles: 348,
      completed_trips: 518,
      passenger_throughput: 8476.363636363638,
      memory_size: 1200,
    },
    {
      episode: 5,
      scenario: "Day 20250707, Cycle 3",
      reward: -299.8041612825012,
      steps: 300,
      time_minutes: 1.4555493315060934,
      avg_loss: 0.13340920741359394,
      epsilon: 0.4876391663457515,
      vehicles: 322,
      completed_trips: 469,
      passenger_throughput: 7674.545454545455,
      memory_size: 1500,
    },
    {
      episode: 6,
      scenario: "Day 20250707, Cycle 1",
      reward: -369.6052521599158,
      steps: 300,
      time_minutes: 1.4771467566490173,
      avg_loss: 0.1583223465581735,
      epsilon: 0.4196991758284578,
      vehicles: 343,
      completed_trips: 477,
      passenger_throughput: 7805.454545454546,
      memory_size: 1800,
    },
    {
      episode: 7,
      scenario: "Day 20250821, Cycle 3",
      reward: -324.6615169487846,
      steps: 300,
      time_minutes: 1.489870015780131,
      avg_loss: 0.1760356593877077,
      epsilon: 0.3612248776305073,
      vehicles: 362,
      completed_trips: 474,
      passenger_throughput: 7756.363636363637,
      memory_size: 2100,
    },
    {
      episode: 8,
      scenario: "Day 20250811, Cycle 2",
      reward: -348.1988639524802,
      steps: 300,
      time_minutes: 1.5041669408480327,
      avg_loss: 0.1828119188050429,
      epsilon: 0.31089747069817225,
      vehicles: 347,
      completed_trips: 487,
      passenger_throughput: 7969.09090909091,
      memory_size: 2400,
    },
    {
      episode: 9,
      scenario: "Day 20250707, Cycle 1",
      reward: -359.336303827365,
      steps: 300,
      time_minutes: 1.507756531238556,
      avg_loss: 0.19275739113489787,
      epsilon: 0.2675818950249339,
      vehicles: 339,
      completed_trips: 485,
      passenger_throughput: 7936.363636363637,
      memory_size: 2700,
    },
    {
      episode: 10,
      scenario: "Day 20250717, Cycle 1",
      reward: -317.29575933483915,
      steps: 300,
      time_minutes: 1.5287955164909364,
      avg_loss: 0.20246390466888745,
      epsilon: 0.23030123205680855,
      vehicles: 352,
      completed_trips: 502,
      passenger_throughput: 8214.545454545456,
      memory_size: 3000,
    },
    {
      episode: 11,
      scenario: "Day 20250703, Cycle 1",
      reward: -340.50682934886095,
      steps: 300,
      time_minutes: 1.5463290691375733,
      avg_loss: 0.2388491684695085,
      epsilon: 0.19821467174354895,
      vehicles: 376,
      completed_trips: 508,
      passenger_throughput: 8312.727272727274,
      memory_size: 3300,
    },
    {
      episode: 12,
      scenario: "Day 20250804, Cycle 2",
      reward: -344.17389577682854,
      steps: 300,
      time_minutes: 1.46446959177653,
      avg_loss: 0.23705022131403286,
      epsilon: 0.17059854931523513,
      vehicles: 354,
      completed_trips: 477,
      passenger_throughput: 7805.454545454546,
      memory_size: 3600,
    },
    {
      episode: 13,
      scenario: "Day 20250708, Cycle 2",
      reward: -332.40357800493183,
      steps: 300,
      time_minutes: 1.5170618136723837,
      avg_loss: 0.23685010438164075,
      epsilon: 0.14683002409689105,
      vehicles: 316,
      completed_trips: 448,
      passenger_throughput: 7330.909090909091,
      memory_size: 3900,
    },
    {
      episode: 14,
      scenario: "Day 20250715, Cycle 1",
      reward: -394.11307803887183,
      steps: 300,
      time_minutes: 1.4936091581980386,
      avg_loss: 0.23159967983762422,
      epsilon: 0.12637303226099805,
      vehicles: 405,
      completed_trips: 498,
      passenger_throughput: 8149.09090909091,
      memory_size: 4200,
    },
    {
      episode: 15,
      scenario: "Day 20250819, Cycle 3",
      reward: -305.7046971963851,
      steps: 300,
      time_minutes: 1.4672331968943277,
      avg_loss: 0.23310857529441514,
      epsilon: 0.1087661967030719,
      vehicles: 328,
      completed_trips: 472,
      passenger_throughput: 7723.636363636364,
      memory_size: 4500,
    },
    {
      episode: 16,
      scenario: "Day 20250812, Cycle 2",
      reward: -311.44413113116553,
      steps: 300,
      time_minutes: 1.434090260664622,
      avg_loss: 0.2360661735634009,
      epsilon: 0.09361242136549094,
      vehicles: 315,
      completed_trips: 467,
      passenger_throughput: 7641.818181818182,
      memory_size: 4800,
    },
    {
      episode: 17,
      scenario: "Day 20250716, Cycle 1",
      reward: -379.5949389887643,
      steps: 300,
      time_minutes: 1.4585560361544292,
      avg_loss: 0.23868239720662435,
      epsilon: 0.08056993532497697,
      vehicles: 350,
      completed_trips: 500,
      passenger_throughput: 8181.818181818182,
      memory_size: 5100,
    },
    {
      episode: 18,
      scenario: "Day 20250821, Cycle 1",
      reward: -354.61283210168074,
      steps: 300,
      time_minutes: 1.4475462277730307,
      avg_loss: 0.23984043861428897,
      epsilon: 0.0693445846564117,
      vehicles: 329,
      completed_trips: 514,
      passenger_throughput: 8410.909090909092,
      memory_size: 5400,
    },
    {
      episode: 19,
      scenario: "Day 20250717, Cycle 3",
      reward: -274.57597545022224,
      steps: 300,
      time_minutes: 1.4603628118832905,
      avg_loss: 0.24040300558010738,
      epsilon: 0.059683198227410465,
      vehicles: 356,
      completed_trips: 505,
      passenger_throughput: 8263.636363636364,
      memory_size: 5700,
    },
    {
      episode: 20,
      scenario: "Day 20250707, Cycle 1",
      reward: -327.6787918771164,
      steps: 300,
      time_minutes: 1.4497150778770447,
      avg_loss: 0.24512152562538783,
      epsilon: 0.05136787779899155,
      vehicles: 342,
      completed_trips: 490,
      passenger_throughput: 8018.181818181819,
      memory_size: 6000,
    },
    {
      episode: 21,
      scenario: "Day 20250818, Cycle 3",
      reward: -343.5912852916351,
      steps: 300,
      time_minutes: 1.4580326199531555,
      avg_loss: 0.245809782097737,
      epsilon: 0.04421108365403042,
      vehicles: 339,
      completed_trips: 453,
      passenger_throughput: 7412.727272727273,
      memory_size: 6300,
    },
    {
      episode: 22,
      scenario: "Day 20250715, Cycle 2",
      reward: -371.33169994068186,
      steps: 300,
      time_minutes: 1.455580472946167,
      avg_loss: 0.24089183365305264,
      epsilon: 0.03805140491714159,
      vehicles: 314,
      completed_trips: 471,
      passenger_throughput: 7707.272727272728,
      memory_size: 6600,
    },
    {
      episode: 23,
      scenario: "Day 20250716, Cycle 3",
      reward: -315.1843193460912,
      steps: 300,
      time_minutes: 1.4703974763552348,
      avg_loss: 0.23529787103335062,
      epsilon: 0.03274991917182452,
      vehicles: 358,
      completed_trips: 511,
      passenger_throughput: 8361.818181818182,
      memory_size: 6900,
    },
    {
      episode: 24,
      scenario: "Day 20250707, Cycle 3",
      reward: -214.60394276116918,
      steps: 300,
      time_minutes: 1.4628688891728718,
      avg_loss: 0.23372879644234976,
      epsilon: 0.02818705927144017,
      vehicles: 314,
      completed_trips: 467,
      passenger_throughput: 7641.818181818182,
      memory_size: 7200,
    },
    {
      episode: 25,
      scenario: "Day 20250707, Cycle 1",
      reward: -348.18064295869726,
      steps: 300,
      time_minutes: 1.4737197518348695,
      avg_loss: 0.22536932239929836,
      epsilon: 0.02425991667958724,
      vehicles: 344,
      completed_trips: 492,
      passenger_throughput: 8050.909090909092,
      memory_size: 7500,
    },
    {
      episode: 26,
      scenario: "Day 20250811, Cycle 3",
      reward: -421.4882146883316,
      steps: 300,
      time_minutes: 1.4764257311820983,
      avg_loss: 0.2163833416501681,
      epsilon: 0.020879920520720754,
      vehicles: 357,
      completed_trips: 476,
      passenger_throughput: 7789.09090909091,
      memory_size: 7800,
    },
    {
      episode: 27,
      scenario: "Day 20250812, Cycle 2",
      reward: -209.18564883516726,
      steps: 300,
      time_minutes: 1.4690881848335267,
      avg_loss: 0.21201600457231204,
      epsilon: 0.01797083999544194,
      vehicles: 302,
      completed_trips: 481,
      passenger_throughput: 7870.909090909092,
      memory_size: 8100,
    },
    {
      episode: 28,
      scenario: "Day 20250812, Cycle 3",
      reward: -379.3360974366876,
      steps: 300,
      time_minutes: 1.4886151830355325,
      avg_loss: 0.21374741743008296,
      epsilon: 0.015467065107900512,
      vehicles: 359,
      completed_trips: 501,
      passenger_throughput: 8198.181818181818,
      memory_size: 8400,
    },
    {
      episode: 29,
      scenario: "Day 20250703, Cycle 2",
      reward: -351.5204896216591,
      steps: 300,
      time_minutes: 1.4819093227386475,
      avg_loss: 0.21707688212394716,
      epsilon: 0.013312126929665567,
      vehicles: 364,
      completed_trips: 534,
      passenger_throughput: 8738.181818181818,
      memory_size: 8700,
    },
    {
      episode: 30,
      scenario: "Day 20250812, Cycle 2",
      reward: -300.3162088909126,
      steps: 300,
      time_minutes: 1.4692669669787088,
      avg_loss: 0.21036993354558944,
      epsilon: 0.011457424026812137,
      vehicles: 311,
      completed_trips: 474,
      passenger_throughput: 7756.363636363637,
      memory_size: 9000,
    },
    {
      episode: 31,
      scenario: "Day 20250818, Cycle 3",
      reward: -340.81969926029603,
      steps: 300,
      time_minutes: 1.4737305402755738,
      avg_loss: 0.1987089382112026,
      epsilon: 0.009995187929535779,
      vehicles: 327,
      completed_trips: 459,
      passenger_throughput: 7510.909090909091,
      memory_size: 9300,
    },
    {
      episode: 32,
      scenario: "Day 20250707, Cycle 1",
      reward: -307.70316102134274,
      steps: 300,
      time_minutes: 1.482692507902781,
      avg_loss: 0.19291449328263602,
      epsilon: 0.009995187929535779,
      vehicles: 345,
      completed_trips: 494,
      passenger_throughput: 8083.636363636364,
      memory_size: 9600,
    },
    {
      episode: 33,
      scenario: "Day 20250708, Cycle 2",
      reward: -332.65072216036276,
      steps: 300,
      time_minutes: 1.472341497739156,
      avg_loss: 0.1942460422217846,
      epsilon: 0.009995187929535779,
      vehicles: 302,
      completed_trips: 454,
      passenger_throughput: 7429.09090909091,
      memory_size: 9900,
    },
    {
      episode: 34,
      scenario: "Day 20250812, Cycle 1",
      reward: -337.7511205601347,
      steps: 300,
      time_minutes: 1.5265706618626913,
      avg_loss: 0.19207383155822755,
      epsilon: 0.009995187929535779,
      vehicles: 371,
      completed_trips: 500,
      passenger_throughput: 8181.818181818182,
      memory_size: 10200,
    },
    {
      episode: 35,
      scenario: "Day 20250811, Cycle 1",
      reward: -319.90765886689485,
      steps: 300,
      time_minutes: 1.5136565486590068,
      avg_loss: 0.19393551141023635,
      epsilon: 0.009995187929535779,
      vehicles: 335,
      completed_trips: 495,
      passenger_throughput: 8100.000000000001,
      memory_size: 10500,
    },
    {
      episode: 36,
      scenario: "Day 20250812, Cycle 1",
      reward: -306.19555971451837,
      steps: 300,
      time_minutes: 1.5001178860664368,
      avg_loss: 0.19674918760855992,
      epsilon: 0.009995187929535779,
      vehicles: 364,
      completed_trips: 533,
      passenger_throughput: 8721.818181818182,
      memory_size: 10800,
    },
    {
      episode: 37,
      scenario: "Day 20250715, Cycle 2",
      reward: -263.5409200048836,
      steps: 300,
      time_minutes: 1.4854326248168945,
      avg_loss: 0.19979244316617648,
      epsilon: 0.009995187929535779,
      vehicles: 321,
      completed_trips: 461,
      passenger_throughput: 7543.636363636364,
      memory_size: 11100,
    },
    {
      episode: 38,
      scenario: "Day 20250818, Cycle 2",
      reward: -355.62880266494386,
      steps: 300,
      time_minutes: 1.4865902463595073,
      avg_loss: 0.19911775385340055,
      epsilon: 0.009995187929535779,
      vehicles: 348,
      completed_trips: 468,
      passenger_throughput: 7658.181818181819,
      memory_size: 11400,
    },
    {
      episode: 39,
      scenario: "Day 20250805, Cycle 1",
      reward: -279.48673439131414,
      steps: 300,
      time_minutes: 1.4971923232078552,
      avg_loss: 0.19759292607506115,
      epsilon: 0.009995187929535779,
      vehicles: 377,
      completed_trips: 484,
      passenger_throughput: 7920.000000000001,
      memory_size: 11700,
    },
    {
      episode: 40,
      scenario: "Day 20250715, Cycle 3",
      reward: -350.9096255811955,
      steps: 300,
      time_minutes: 1.4809839367866515,
      avg_loss: 0.19436436707774798,
      epsilon: 0.009995187929535779,
      vehicles: 342,
      completed_trips: 467,
      passenger_throughput: 7641.818181818182,
      memory_size: 12000,
    },
    {
      episode: 41,
      scenario: "Day 20250821, Cycle 3",
      reward: -334.71059548602716,
      steps: 300,
      time_minutes: 1.495440379778544,
      avg_loss: 0.19638085092107455,
      epsilon: 0.009995187929535779,
      vehicles: 366,
      completed_trips: 480,
      passenger_throughput: 7854.545454545455,
      memory_size: 12300,
    },
    {
      episode: 42,
      scenario: "Day 20250708, Cycle 2",
      reward: -247.91599236530615,
      steps: 300,
      time_minutes: 1.482345445950826,
      avg_loss: 0.19430582200487453,
      epsilon: 0.009995187929535779,
      vehicles: 315,
      completed_trips: 446,
      passenger_throughput: 7298.181818181819,
      memory_size: 12600,
    },
    {
      episode: 43,
      scenario: "Day 20250704, Cycle 1",
      reward: -311.9227038436517,
      steps: 300,
      time_minutes: 1.4859755635261536,
      avg_loss: 0.19106691335638365,
      epsilon: 0.009995187929535779,
      vehicles: 344,
      completed_trips: 485,
      passenger_throughput: 7936.363636363637,
      memory_size: 12900,
    },
    {
      episode: 44,
      scenario: "Day 20250701, Cycle 1",
      reward: -367.27351485744686,
      steps: 300,
      time_minutes: 1.5109273592631023,
      avg_loss: 0.18981593956549964,
      epsilon: 0.009995187929535779,
      vehicles: 391,
      completed_trips: 516,
      passenger_throughput: 8443.636363636364,
      memory_size: 13200,
    },
    {
      episode: 45,
      scenario: "Day 20250717, Cycle 3",
      reward: -302.95985989844894,
      steps: 300,
      time_minutes: 1.4968381881713868,
      avg_loss: 0.18976345419883728,
      epsilon: 0.009995187929535779,
      vehicles: 352,
      completed_trips: 534,
      passenger_throughput: 8738.181818181818,
      memory_size: 13500,
    },
    {
      episode: 46,
      scenario: "Day 20250717, Cycle 2",
      reward: -320.9938955836765,
      steps: 300,
      time_minutes: 1.4981623768806458,
      avg_loss: 0.18948680738608042,
      epsilon: 0.009995187929535779,
      vehicles: 352,
      completed_trips: 523,
      passenger_throughput: 8558.181818181818,
      memory_size: 13800,
    },
    {
      episode: 47,
      scenario: "Day 20250804, Cycle 1",
      reward: -306.2703582847086,
      steps: 300,
      time_minutes: 1.5027555028597515,
      avg_loss: 0.18397135821481544,
      epsilon: 0.009995187929535779,
      vehicles: 355,
      completed_trips: 481,
      passenger_throughput: 7870.909090909092,
      memory_size: 14100,
    },
    {
      episode: 48,
      scenario: "Day 20250812, Cycle 1",
      reward: -373.9085775183728,
      steps: 300,
      time_minutes: 1.5109157005945841,
      avg_loss: 0.1813808916012446,
      epsilon: 0.009995187929535779,
      vehicles: 379,
      completed_trips: 491,
      passenger_throughput: 8034.545454545455,
      memory_size: 14400,
    },
    {
      episode: 49,
      scenario: "Day 20250807, Cycle 2",
      reward: -338.23925317168016,
      steps: 300,
      time_minutes: 1.511540416876475,
      avg_loss: 0.17710688171287378,
      epsilon: 0.009995187929535779,
      vehicles: 379,
      completed_trips: 495,
      passenger_throughput: 8100.000000000001,
      memory_size: 14700,
    },
    {
      episode: 50,
      scenario: "Day 20250709, Cycle 2",
      reward: -382.45854089128574,
      steps: 300,
      time_minutes: 1.4930551608403524,
      avg_loss: 0.17739180001119773,
      epsilon: 0.009995187929535779,
      vehicles: 335,
      completed_trips: 420,
      passenger_throughput: 6872.727272727273,
      memory_size: 15000,
    },
    {
      episode: 51,
      scenario: "Day 20250821, Cycle 3",
      reward: -348.871915894197,
      steps: 300,
      time_minutes: 1.5069603403409322,
      avg_loss: 0.18366913413008054,
      epsilon: 0.009995187929535779,
      vehicles: 348,
      completed_trips: 479,
      passenger_throughput: 7838.181818181819,
      memory_size: 15300,
    },
    {
      episode: 52,
      scenario: "Day 20250716, Cycle 2",
      reward: -314.66220764536985,
      steps: 300,
      time_minutes: 1.501953939596812,
      avg_loss: 0.18014971246321995,
      epsilon: 0.009995187929535779,
      vehicles: 345,
      completed_trips: 508,
      passenger_throughput: 8312.727272727274,
      memory_size: 15600,
    },
    {
      episode: 53,
      scenario: "Day 20250818, Cycle 2",
      reward: -380.36842846567436,
      steps: 300,
      time_minutes: 1.4929393609364827,
      avg_loss: 0.18555223653713862,
      epsilon: 0.009995187929535779,
      vehicles: 341,
      completed_trips: 470,
      passenger_throughput: 7690.909090909092,
      memory_size: 15900,
    },
    {
      episode: 54,
      scenario: "Day 20250708, Cycle 2",
      reward: -276.7610124127168,
      steps: 300,
      time_minutes: 1.4883554895718893,
      avg_loss: 0.18543195943037669,
      epsilon: 0.009995187929535779,
      vehicles: 312,
      completed_trips: 454,
      passenger_throughput: 7429.09090909091,
      memory_size: 16200,
    },
    {
      episode: 55,
      scenario: "Day 20250716, Cycle 3",
      reward: -372.8181862091669,
      steps: 300,
      time_minutes: 1.4977256655693054,
      avg_loss: 0.17753149273494878,
      epsilon: 0.009995187929535779,
      vehicles: 347,
      completed_trips: 512,
      passenger_throughput: 8378.181818181818,
      memory_size: 16500,
    },
    {
      episode: 56,
      scenario: "Day 20250717, Cycle 1",
      reward: -333.09430755225577,
      steps: 300,
      time_minutes: 1.50004669825236,
      avg_loss: 0.1746271388977766,
      epsilon: 0.009995187929535779,
      vehicles: 354,
      completed_trips: 494,
      passenger_throughput: 8083.636363636364,
      memory_size: 16800,
    },
    {
      episode: 57,
      scenario: "Day 20250703, Cycle 3",
      reward: -279.5188430041193,
      steps: 300,
      time_minutes: 1.508263846238454,
      avg_loss: 0.1730382830897967,
      epsilon: 0.009995187929535779,
      vehicles: 351,
      completed_trips: 507,
      passenger_throughput: 8296.363636363638,
      memory_size: 17100,
    },
    {
      episode: 58,
      scenario: "Day 20250812, Cycle 1",
      reward: -339.0412499027448,
      steps: 300,
      time_minutes: 1.5083980838457742,
      avg_loss: 0.17243712765475114,
      epsilon: 0.009995187929535779,
      vehicles: 370,
      completed_trips: 513,
      passenger_throughput: 8394.545454545456,
      memory_size: 17400,
    },
    {
      episode: 59,
      scenario: "Day 20250708, Cycle 1",
      reward: -366.937181509686,
      steps: 300,
      time_minutes: 1.5010580658912658,
      avg_loss: 0.17384454642732938,
      epsilon: 0.009995187929535779,
      vehicles: 331,
      completed_trips: 461,
      passenger_throughput: 7543.636363636364,
      memory_size: 17700,
    },
    {
      episode: 60,
      scenario: "Day 20250807, Cycle 3",
      reward: -371.3037534667853,
      steps: 300,
      time_minutes: 1.498726749420166,
      avg_loss: 0.17170949541032315,
      epsilon: 0.009995187929535779,
      vehicles: 352,
      completed_trips: 473,
      passenger_throughput: 7740.000000000001,
      memory_size: 18000,
    },
    {
      episode: 61,
      scenario: "Day 20250717, Cycle 3",
      reward: -251.52698519981675,
      steps: 300,
      time_minutes: 1.5695659597714742,
      avg_loss: 0.18202663791676363,
      epsilon: 0.009995187929535779,
      vehicles: 352,
      completed_trips: 520,
      passenger_throughput: 8509.09090909091,
      memory_size: 18300,
    },
    {
      episode: 62,
      scenario: "Day 20250809, Cycle 3",
      reward: -349.07174744554675,
      steps: 300,
      time_minutes: 1.5667426188786824,
      avg_loss: 0.1791687039534251,
      epsilon: 0.009995187929535779,
      vehicles: 355,
      completed_trips: 476,
      passenger_throughput: 7789.09090909091,
      memory_size: 18600,
    },
    {
      episode: 63,
      scenario: "Day 20250703, Cycle 2",
      reward: -232.0551728833637,
      steps: 300,
      time_minutes: 1.5720803340276082,
      avg_loss: 0.18298042563100655,
      epsilon: 0.009995187929535779,
      vehicles: 373,
      completed_trips: 513,
      passenger_throughput: 8394.545454545456,
      memory_size: 18900,
    },
    {
      episode: 64,
      scenario: "Day 20250811, Cycle 1",
      reward: -270.1882289639829,
      steps: 300,
      time_minutes: 1.5628055651982626,
      avg_loss: 0.18474384926259518,
      epsilon: 0.009995187929535779,
      vehicles: 329,
      completed_trips: 507,
      passenger_throughput: 8296.363636363638,
      memory_size: 19200,
    },
    {
      episode: 65,
      scenario: "Day 20250701, Cycle 1",
      reward: -340.8217063460972,
      steps: 300,
      time_minutes: 1.5860705097516379,
      avg_loss: 0.1879831664264202,
      epsilon: 0.009995187929535779,
      vehicles: 380,
      completed_trips: 515,
      passenger_throughput: 8427.272727272728,
      memory_size: 19500,
    },
    {
      episode: 66,
      scenario: "Day 20250821, Cycle 2",
      reward: -284.65694389010685,
      steps: 300,
      time_minutes: 1.5549067298571269,
      avg_loss: 0.18519710883498192,
      epsilon: 0.009995187929535779,
      vehicles: 318,
      completed_trips: 478,
      passenger_throughput: 7821.818181818182,
      memory_size: 19800,
    },
    {
      episode: 67,
      scenario: "Day 20250716, Cycle 1",
      reward: -353.5209924630674,
      steps: 300,
      time_minutes: 1.5826281905174255,
      avg_loss: 0.18234373301267623,
      epsilon: 0.009995187929535779,
      vehicles: 355,
      completed_trips: 502,
      passenger_throughput: 8214.545454545456,
      memory_size: 20100,
    },
    {
      episode: 68,
      scenario: "Day 20250709, Cycle 3",
      reward: -331.1821496197887,
      steps: 300,
      time_minutes: 1.5624900341033936,
      avg_loss: 0.18032498511175316,
      epsilon: 0.009995187929535779,
      vehicles: 326,
      completed_trips: 453,
      passenger_throughput: 7412.727272727273,
      memory_size: 20400,
    },
    {
      episode: 69,
      scenario: "Day 20250708, Cycle 2",
      reward: -324.0353257364991,
      steps: 300,
      time_minutes: 1.5594160079956054,
      avg_loss: 0.17759640698631604,
      epsilon: 0.009995187929535779,
      vehicles: 309,
      completed_trips: 453,
      passenger_throughput: 7412.727272727273,
      memory_size: 20700,
    },
    {
      episode: 70,
      scenario: "Day 20250715, Cycle 2",
      reward: -334.8165818656501,
      steps: 300,
      time_minutes: 1.5657668113708496,
      avg_loss: 0.17140431637565295,
      epsilon: 0.009995187929535779,
      vehicles: 325,
      completed_trips: 455,
      passenger_throughput: 7445.454545454546,
      memory_size: 21000,
    },
    {
      episode: 71,
      scenario: "Day 20250709, Cycle 1",
      reward: -244.47593591735105,
      steps: 300,
      time_minutes: 1.5693758686383565,
      avg_loss: 0.16409796553353467,
      epsilon: 0.009995187929535779,
      vehicles: 317,
      completed_trips: 466,
      passenger_throughput: 7625.454545454546,
      memory_size: 21300,
    },
    {
      episode: 72,
      scenario: "Day 20250715, Cycle 2",
      reward: -306.21043682038106,
      steps: 300,
      time_minutes: 1.5706332723299663,
      avg_loss: 0.1654732154806455,
      epsilon: 0.009995187929535779,
      vehicles: 324,
      completed_trips: 454,
      passenger_throughput: 7429.09090909091,
      memory_size: 21600,
    },
    {
      episode: 73,
      scenario: "Day 20250704, Cycle 1",
      reward: -364.4852156203844,
      steps: 300,
      time_minutes: 1.5741735577583313,
      avg_loss: 0.16331385997434458,
      epsilon: 0.009995187929535779,
      vehicles: 339,
      completed_trips: 490,
      passenger_throughput: 8018.181818181819,
      memory_size: 21900,
    },
    {
      episode: 74,
      scenario: "Day 20250809, Cycle 2",
      reward: -311.0859664753007,
      steps: 300,
      time_minutes: 1.5867697278658548,
      avg_loss: 0.16093305086096127,
      epsilon: 0.009995187929535779,
      vehicles: 367,
      completed_trips: 500,
      passenger_throughput: 8181.818181818182,
      memory_size: 22200,
    },
    {
      episode: 75,
      scenario: "Day 20250703, Cycle 3",
      reward: -307.9902595943206,
      steps: 300,
      time_minutes: 1.5878063797950746,
      avg_loss: 0.16090915329754352,
      epsilon: 0.009995187929535779,
      vehicles: 359,
      completed_trips: 504,
      passenger_throughput: 8247.272727272728,
      memory_size: 22500,
    },
    {
      episode: 76,
      scenario: "Day 20250819, Cycle 2",
      reward: -284.8125980410018,
      steps: 300,
      time_minutes: 1.5763124108314515,
      avg_loss: 0.16480283950765928,
      epsilon: 0.009995187929535779,
      vehicles: 329,
      completed_trips: 464,
      passenger_throughput: 7592.727272727273,
      memory_size: 22800,
    },
    {
      episode: 77,
      scenario: "Day 20250707, Cycle 1",
      reward: -287.2119051957504,
      steps: 300,
      time_minutes: 1.5740944425264993,
      avg_loss: 0.15892854827145736,
      epsilon: 0.009995187929535779,
      vehicles: 345,
      completed_trips: 494,
      passenger_throughput: 8083.636363636364,
      memory_size: 23100,
    },
    {
      episode: 78,
      scenario: "Day 20250812, Cycle 3",
      reward: -374.3879351261344,
      steps: 300,
      time_minutes: 1.5895100394884745,
      avg_loss: 0.15950956732034682,
      epsilon: 0.009995187929535779,
      vehicles: 350,
      completed_trips: 504,
      passenger_throughput: 8247.272727272728,
      memory_size: 23400,
    },
    {
      episode: 79,
      scenario: "Day 20250704, Cycle 1",
      reward: -369.5994902957429,
      steps: 300,
      time_minutes: 1.583115295569102,
      avg_loss: 0.15851919375360013,
      epsilon: 0.009995187929535779,
      vehicles: 340,
      completed_trips: 496,
      passenger_throughput: 8116.363636363637,
      memory_size: 23700,
    },
    {
      episode: 80,
      scenario: "Day 20250821, Cycle 3",
      reward: -333.83549110260907,
      steps: 300,
      time_minutes: 1.596863313515981,
      avg_loss: 0.1563542082409064,
      epsilon: 0.009995187929535779,
      vehicles: 349,
      completed_trips: 477,
      passenger_throughput: 7805.454545454546,
      memory_size: 24000,
    },
    {
      episode: 81,
      scenario: "Day 20250703, Cycle 3",
      reward: -364.91563947052396,
      steps: 300,
      time_minutes: 1.5981798887252807,
      avg_loss: 0.15153087774912516,
      epsilon: 0.009995187929535779,
      vehicles: 341,
      completed_trips: 521,
      passenger_throughput: 8525.454545454546,
      memory_size: 24300,
    },
    {
      episode: 82,
      scenario: "Day 20250811, Cycle 3",
      reward: -362.90822514239306,
      steps: 300,
      time_minutes: 1.5930117845535279,
      avg_loss: 0.15029251642525196,
      epsilon: 0.009995187929535779,
      vehicles: 360,
      completed_trips: 482,
      passenger_throughput: 7887.272727272728,
      memory_size: 24600,
    },
    {
      episode: 83,
      scenario: "Day 20250703, Cycle 2",
      reward: -345.58137947237384,
      steps: 300,
      time_minutes: 1.6044952074686687,
      avg_loss: 0.15282876747349897,
      epsilon: 0.009995187929535779,
      vehicles: 381,
      completed_trips: 521,
      passenger_throughput: 8525.454545454546,
      memory_size: 24900,
    },
    {
      episode: 84,
      scenario: "Day 20250811, Cycle 2",
      reward: -351.3416193517497,
      steps: 300,
      time_minutes: 1.601373819510142,
      avg_loss: 0.1543216412762801,
      epsilon: 0.009995187929535779,
      vehicles: 363,
      completed_trips: 477,
      passenger_throughput: 7805.454545454546,
      memory_size: 25200,
    },
    {
      episode: 85,
      scenario: "Day 20250804, Cycle 1",
      reward: -333.96560278102316,
      steps: 300,
      time_minutes: 1.5951358040173849,
      avg_loss: 0.1527288331091404,
      epsilon: 0.009995187929535779,
      vehicles: 349,
      completed_trips: 488,
      passenger_throughput: 7985.454545454546,
      memory_size: 25500,
    },
    {
      episode: 86,
      scenario: "Day 20250811, Cycle 2",
      reward: -335.31686233852787,
      steps: 300,
      time_minutes: 1.5982314984003703,
      avg_loss: 0.15185318904618422,
      epsilon: 0.009995187929535779,
      vehicles: 370,
      completed_trips: 471,
      passenger_throughput: 7707.272727272728,
      memory_size: 25800,
    },
    {
      episode: 87,
      scenario: "Day 20250812, Cycle 3",
      reward: -364.8175683510698,
      steps: 300,
      time_minutes: 1.6053171356519063,
      avg_loss: 0.15350133093694845,
      epsilon: 0.009995187929535779,
      vehicles: 358,
      completed_trips: 511,
      passenger_throughput: 8361.818181818182,
      memory_size: 26100,
    },
    {
      episode: 88,
      scenario: "Day 20250704, Cycle 3",
      reward: -393.5118885310129,
      steps: 300,
      time_minutes: 1.6106372912724813,
      avg_loss: 0.15217998651166756,
      epsilon: 0.009995187929535779,
      vehicles: 377,
      completed_trips: 484,
      passenger_throughput: 7920.000000000001,
      memory_size: 26400,
    },
    {
      episode: 89,
      scenario: "Day 20250809, Cycle 2",
      reward: -323.56092149004337,
      steps: 300,
      time_minutes: 1.6148688197135925,
      avg_loss: 0.15371453031897545,
      epsilon: 0.009995187929535779,
      vehicles: 372,
      completed_trips: 491,
      passenger_throughput: 8034.545454545455,
      memory_size: 26700,
    },
    {
      episode: 90,
      scenario: "Day 20250715, Cycle 2",
      reward: -300.2982904848736,
      steps: 300,
      time_minutes: 1.614511748154958,
      avg_loss: 0.155100871399045,
      epsilon: 0.009995187929535779,
      vehicles: 312,
      completed_trips: 467,
      passenger_throughput: 7641.818181818182,
      memory_size: 27000,
    },
    {
      episode: 91,
      scenario: "Day 20250821, Cycle 3",
      reward: -311.49619887894943,
      steps: 300,
      time_minutes: 1.621081244945526,
      avg_loss: 0.16080088717242083,
      epsilon: 0.009995187929535779,
      vehicles: 356,
      completed_trips: 475,
      passenger_throughput: 7772.727272727273,
      memory_size: 27300,
    },
    {
      episode: 92,
      scenario: "Day 20250717, Cycle 1",
      reward: -318.7989131259547,
      steps: 300,
      time_minutes: 1.6276573300361634,
      avg_loss: 0.15291826248168947,
      epsilon: 0.009995187929535779,
      vehicles: 355,
      completed_trips: 486,
      passenger_throughput: 7952.727272727273,
      memory_size: 27600,
    },
    {
      episode: 93,
      scenario: "Day 20250704, Cycle 3",
      reward: -378.30089691383137,
      steps: 300,
      time_minutes: 1.6390284140904745,
      avg_loss: 0.1490973847359419,
      epsilon: 0.009995187929535779,
      vehicles: 387,
      completed_trips: 491,
      passenger_throughput: 8034.545454545455,
      memory_size: 27900,
    },
    {
      episode: 94,
      scenario: "Day 20250716, Cycle 3",
      reward: -289.74482480969823,
      steps: 300,
      time_minutes: 1.6375846147537232,
      avg_loss: 0.14934078680972257,
      epsilon: 0.009995187929535779,
      vehicles: 360,
      completed_trips: 511,
      passenger_throughput: 8361.818181818182,
      memory_size: 28200,
    },
    {
      episode: 95,
      scenario: "Day 20250818, Cycle 2",
      reward: -260.74308332653237,
      steps: 300,
      time_minutes: 1.6269672950108847,
      avg_loss: 0.15190326273441315,
      epsilon: 0.009995187929535779,
      vehicles: 321,
      completed_trips: 486,
      passenger_throughput: 7952.727272727273,
      memory_size: 28500,
    },
    {
      episode: 96,
      scenario: "Day 20250807, Cycle 2",
      reward: -375.8064194735997,
      steps: 300,
      time_minutes: 1.6482834180196126,
      avg_loss: 0.1503892692178488,
      epsilon: 0.009995187929535779,
      vehicles: 367,
      completed_trips: 488,
      passenger_throughput: 7985.454545454546,
      memory_size: 28800,
    },
    {
      episode: 97,
      scenario: "Day 20250716, Cycle 3",
      reward: -305.9812913187266,
      steps: 300,
      time_minutes: 1.6428504546483358,
      avg_loss: 0.14544510381917158,
      epsilon: 0.009995187929535779,
      vehicles: 341,
      completed_trips: 518,
      passenger_throughput: 8476.363636363638,
      memory_size: 29100,
    },
    {
      episode: 98,
      scenario: "Day 20250821, Cycle 2",
      reward: -370.7499746794323,
      steps: 300,
      time_minutes: 1.6291756510734559,
      avg_loss: 0.1517863871405522,
      epsilon: 0.009995187929535779,
      vehicles: 336,
      completed_trips: 471,
      passenger_throughput: 7707.272727272728,
      memory_size: 29400,
    },
    {
      episode: 99,
      scenario: "Day 20250819, Cycle 3",
      reward: -347.83771193568003,
      steps: 300,
      time_minutes: 1.6859972675641377,
      avg_loss: 0.14540316936870415,
      epsilon: 0.009995187929535779,
      vehicles: 330,
      completed_trips: 478,
      passenger_throughput: 7821.818181818182,
      memory_size: 29700,
    },
    {
      episode: 100,
      scenario: "Day 20250818, Cycle 2",
      reward: -335.9568026706325,
      steps: 300,
      time_minutes: 1.6395610372225444,
      avg_loss: 0.14506704551478228,
      epsilon: 0.009995187929535779,
      vehicles: 325,
      completed_trips: 478,
      passenger_throughput: 7821.818181818182,
      memory_size: 30000,
    },
    {
      episode: 101,
      scenario: "Day 20250703, Cycle 2",
      reward: -353.68604032074006,
      steps: 300,
      time_minutes: 1.644161876042684,
      avg_loss: 0.1396401016910871,
      epsilon: 0.009995187929535779,
      vehicles: 365,
      completed_trips: 517,
      passenger_throughput: 8460.0,
      memory_size: 30300,
    },
    {
      episode: 102,
      scenario: "Day 20250715, Cycle 3",
      reward: -327.74080412314675,
      steps: 300,
      time_minutes: 1.6345210909843444,
      avg_loss: 0.13704903525610765,
      epsilon: 0.009995187929535779,
      vehicles: 339,
      completed_trips: 464,
      passenger_throughput: 7592.727272727273,
      memory_size: 30600,
    },
    {
      episode: 103,
      scenario: "Day 20250805, Cycle 1",
      reward: -356.9435600062214,
      steps: 300,
      time_minutes: 1.6432632486025491,
      avg_loss: 0.13544588046769301,
      epsilon: 0.009995187929535779,
      vehicles: 356,
      completed_trips: 484,
      passenger_throughput: 7920.000000000001,
      memory_size: 30900,
    },
    {
      episode: 104,
      scenario: "Day 20250818, Cycle 2",
      reward: -334.99497579491793,
      steps: 300,
      time_minutes: 1.6347248395284018,
      avg_loss: 0.13138632401823996,
      epsilon: 0.009995187929535779,
      vehicles: 334,
      completed_trips: 478,
      passenger_throughput: 7821.818181818182,
      memory_size: 31200,
    },
    {
      episode: 105,
      scenario: "Day 20250703, Cycle 3",
      reward: -313.0850947598425,
      steps: 300,
      time_minutes: 1.6533281207084656,
      avg_loss: 0.13003637303908666,
      epsilon: 0.009995187929535779,
      vehicles: 344,
      completed_trips: 514,
      passenger_throughput: 8410.909090909092,
      memory_size: 31500,
    },
    {
      episode: 106,
      scenario: "Day 20250821, Cycle 3",
      reward: -327.7238540180472,
      steps: 300,
      time_minutes: 1.6451830546061197,
      avg_loss: 0.13201440028846265,
      epsilon: 0.009995187929535779,
      vehicles: 347,
      completed_trips: 485,
      passenger_throughput: 7936.363636363637,
      memory_size: 31800,
    },
    {
      episode: 107,
      scenario: "Day 20250717, Cycle 2",
      reward: -259.6664362918654,
      steps: 300,
      time_minutes: 1.652500589688619,
      avg_loss: 0.1284248102704684,
      epsilon: 0.009995187929535779,
      vehicles: 362,
      completed_trips: 502,
      passenger_throughput: 8214.545454545456,
      memory_size: 32100,
    },
    {
      episode: 108,
      scenario: "Day 20250707, Cycle 1",
      reward: -366.30285565020114,
      steps: 300,
      time_minutes: 1.6456493576367697,
      avg_loss: 0.13258707503477732,
      epsilon: 0.009995187929535779,
      vehicles: 353,
      completed_trips: 486,
      passenger_throughput: 7952.727272727273,
      memory_size: 32400,
    },
    {
      episode: 109,
      scenario: "Day 20250819, Cycle 3",
      reward: -284.05109964812414,
      steps: 300,
      time_minutes: 1.6378155867258708,
      avg_loss: 0.1373467833052079,
      epsilon: 0.009995187929535779,
      vehicles: 329,
      completed_trips: 462,
      passenger_throughput: 7560.000000000001,
      memory_size: 32700,
    },
    {
      episode: 110,
      scenario: "Day 20250807, Cycle 2",
      reward: -339.0368791372111,
      steps: 300,
      time_minutes: 1.6553607344627381,
      avg_loss: 0.13956601890424888,
      epsilon: 0.009995187929535779,
      vehicles: 368,
      completed_trips: 489,
      passenger_throughput: 8001.818181818182,
      memory_size: 33000,
    },
    {
      episode: 111,
      scenario: "Day 20250821, Cycle 1",
      reward: -326.3862594234735,
      steps: 300,
      time_minutes: 1.6678980310757956,
      avg_loss: 0.14926198698580265,
      epsilon: 0.009995187929535779,
      vehicles: 336,
      completed_trips: 504,
      passenger_throughput: 8247.272727272728,
      memory_size: 33300,
    },
    {
      episode: 112,
      scenario: "Day 20250708, Cycle 1",
      reward: -362.41928613106717,
      steps: 300,
      time_minutes: 1.660927693049113,
      avg_loss: 0.1380895801136891,
      epsilon: 0.009995187929535779,
      vehicles: 318,
      completed_trips: 468,
      passenger_throughput: 7658.181818181819,
      memory_size: 33600,
    },
    {
      episode: 113,
      scenario: "Day 20250709, Cycle 1",
      reward: -361.3777168066709,
      steps: 300,
      time_minutes: 1.6653115312258402,
      avg_loss: 0.13680507478614648,
      epsilon: 0.009995187929535779,
      vehicles: 334,
      completed_trips: 468,
      passenger_throughput: 7658.181818181819,
      memory_size: 33900,
    },
    {
      episode: 114,
      scenario: "Day 20250710, Cycle 2",
      reward: -330.96249106833204,
      steps: 300,
      time_minutes: 1.6592031677563985,
      avg_loss: 0.13321293180187543,
      epsilon: 0.009995187929535779,
      vehicles: 301,
      completed_trips: 458,
      passenger_throughput: 7494.545454545455,
      memory_size: 34200,
    },
    {
      episode: 115,
      scenario: "Day 20250704, Cycle 3",
      reward: -429.560206133902,
      steps: 300,
      time_minutes: 1.6836648384730022,
      avg_loss: 0.13184798416992027,
      epsilon: 0.009995187929535779,
      vehicles: 405,
      completed_trips: 482,
      passenger_throughput: 7887.272727272728,
      memory_size: 34500,
    },
    {
      episode: 116,
      scenario: "Day 20250811, Cycle 2",
      reward: -300.16339979723426,
      steps: 300,
      time_minutes: 1.670484753449758,
      avg_loss: 0.13195976170400778,
      epsilon: 0.009995187929535779,
      vehicles: 355,
      completed_trips: 473,
      passenger_throughput: 7740.000000000001,
      memory_size: 34800,
    },
    {
      episode: 117,
      scenario: "Day 20250815, Cycle 3",
      reward: -303.49866707527957,
      steps: 300,
      time_minutes: 1.6615689833958944,
      avg_loss: 0.13185016562541327,
      epsilon: 0.009995187929535779,
      vehicles: 317,
      completed_trips: 471,
      passenger_throughput: 7707.272727272728,
      memory_size: 35100,
    },
    {
      episode: 118,
      scenario: "Day 20250812, Cycle 1",
      reward: -367.73998558836604,
      steps: 300,
      time_minutes: 1.6791910171508788,
      avg_loss: 0.13145179122686387,
      epsilon: 0.009995187929535779,
      vehicles: 368,
      completed_trips: 508,
      passenger_throughput: 8312.727272727274,
      memory_size: 35400,
    },
    {
      episode: 119,
      scenario: "Day 20250704, Cycle 3",
      reward: -376.9488657245695,
      steps: 300,
      time_minutes: 1.6788958191871644,
      avg_loss: 0.12933633086582025,
      epsilon: 0.009995187929535779,
      vehicles: 382,
      completed_trips: 494,
      passenger_throughput: 8083.636363636364,
      memory_size: 35700,
    },
    {
      episode: 120,
      scenario: "Day 20250716, Cycle 2",
      reward: -324.7414854344307,
      steps: 300,
      time_minutes: 1.6796717564264934,
      avg_loss: 0.12575936056673526,
      epsilon: 0.009995187929535779,
      vehicles: 342,
      completed_trips: 522,
      passenger_throughput: 8541.818181818182,
      memory_size: 36000,
    },
    {
      episode: 121,
      scenario: "Day 20250709, Cycle 1",
      reward: -384.05267658334975,
      steps: 300,
      time_minutes: 1.673898708820343,
      avg_loss: 0.1392849770685037,
      epsilon: 0.009995187929535779,
      vehicles: 316,
      completed_trips: 479,
      passenger_throughput: 7838.181818181819,
      memory_size: 36300,
    },
    {
      episode: 122,
      scenario: "Day 20250821, Cycle 3",
      reward: -337.86340932306047,
      steps: 300,
      time_minutes: 1.6853320558865865,
      avg_loss: 0.13452706600228945,
      epsilon: 0.009995187929535779,
      vehicles: 359,
      completed_trips: 482,
      passenger_throughput: 7887.272727272728,
      memory_size: 36600,
    },
    {
      episode: 123,
      scenario: "Day 20250717, Cycle 2",
      reward: -376.6618186179721,
      steps: 300,
      time_minutes: 1.6959136684735616,
      avg_loss: 0.12674878465632597,
      epsilon: 0.009995187929535779,
      vehicles: 360,
      completed_trips: 508,
      passenger_throughput: 8312.727272727274,
      memory_size: 36900,
    },
    {
      episode: 124,
      scenario: "Day 20250703, Cycle 2",
      reward: -356.5376136185911,
      steps: 300,
      time_minutes: 1.7059848189353943,
      avg_loss: 0.12243503225346407,
      epsilon: 0.009995187929535779,
      vehicles: 374,
      completed_trips: 532,
      passenger_throughput: 8705.454545454546,
      memory_size: 37200,
    },
    {
      episode: 125,
      scenario: "Day 20250715, Cycle 2",
      reward: -314.1776811272425,
      steps: 300,
      time_minutes: 1.6910425225893657,
      avg_loss: 0.12168421124418577,
      epsilon: 0.009995187929535779,
      vehicles: 317,
      completed_trips: 458,
      passenger_throughput: 7494.545454545455,
      memory_size: 37500,
    },
    {
      episode: 126,
      scenario: "Day 20250818, Cycle 3",
      reward: -368.4251739481398,
      steps: 300,
      time_minutes: 1.6940658728281657,
      avg_loss: 0.11976924868921439,
      epsilon: 0.009995187929535779,
      vehicles: 344,
      completed_trips: 419,
      passenger_throughput: 6856.363636363637,
      memory_size: 37800,
    },
    {
      episode: 127,
      scenario: "Day 20250821, Cycle 1",
      reward: -339.77090681692215,
      steps: 300,
      time_minutes: 1.712019431591034,
      avg_loss: 0.11996930179496607,
      epsilon: 0.009995187929535779,
      vehicles: 334,
      completed_trips: 502,
      passenger_throughput: 8214.545454545456,
      memory_size: 38100,
    },
    {
      episode: 128,
      scenario: "Day 20250821, Cycle 2",
      reward: -313.2070869275282,
      steps: 300,
      time_minutes: 1.7149247527122498,
      avg_loss: 0.12195073096702497,
      epsilon: 0.009995187929535779,
      vehicles: 353,
      completed_trips: 451,
      passenger_throughput: 7380.000000000001,
      memory_size: 38400,
    },
    {
      episode: 129,
      scenario: "Day 20250701, Cycle 1",
      reward: -362.6879700123687,
      steps: 300,
      time_minutes: 1.7712412556012471,
      avg_loss: 0.12164758081237476,
      epsilon: 0.009995187929535779,
      vehicles: 380,
      completed_trips: 525,
      passenger_throughput: 8590.909090909092,
      memory_size: 38700,
    },
    {
      episode: 130,
      scenario: "Day 20250707, Cycle 1",
      reward: -369.9081195370868,
      steps: 300,
      time_minutes: 1.7506776014963785,
      avg_loss: 0.11881293691694736,
      epsilon: 0.009995187929535779,
      vehicles: 356,
      completed_trips: 469,
      passenger_throughput: 7674.545454545455,
      memory_size: 39000,
    },
    {
      episode: 131,
      scenario: "Day 20250708, Cycle 2",
      reward: -291.81813665839877,
      steps: 300,
      time_minutes: 1.7291369756062827,
      avg_loss: 0.11412407177189986,
      epsilon: 0.009995187929535779,
      vehicles: 308,
      completed_trips: 465,
      passenger_throughput: 7609.09090909091,
      memory_size: 39300,
    },
    {
      episode: 132,
      scenario: "Day 20250717, Cycle 2",
      reward: -358.36000828439256,
      steps: 300,
      time_minutes: 1.7237292170524596,
      avg_loss: 0.11212420913080375,
      epsilon: 0.009995187929535779,
      vehicles: 345,
      completed_trips: 521,
      passenger_throughput: 8525.454545454546,
      memory_size: 39600,
    },
    {
      episode: 133,
      scenario: "Day 20250707, Cycle 3",
      reward: -288.7223049873371,
      steps: 300,
      time_minutes: 1.7121973474820456,
      avg_loss: 0.11203851468861104,
      epsilon: 0.009995187929535779,
      vehicles: 300,
      completed_trips: 477,
      passenger_throughput: 7805.454545454546,
      memory_size: 39900,
    },
    {
      episode: 134,
      scenario: "Day 20250716, Cycle 2",
      reward: -364.3994237531574,
      steps: 300,
      time_minutes: 1.7293914079666137,
      avg_loss: 0.11478016806145509,
      epsilon: 0.009995187929535779,
      vehicles: 344,
      completed_trips: 503,
      passenger_throughput: 8230.909090909092,
      memory_size: 40200,
    },
    {
      episode: 135,
      scenario: "Day 20250818, Cycle 3",
      reward: -368.0349731202416,
      steps: 300,
      time_minutes: 1.7224257707595825,
      avg_loss: 0.11278123952448368,
      epsilon: 0.009995187929535779,
      vehicles: 340,
      completed_trips: 468,
      passenger_throughput: 7658.181818181819,
      memory_size: 40500,
    },
    {
      episode: 136,
      scenario: "Day 20250715, Cycle 3",
      reward: -315.84833192832826,
      steps: 300,
      time_minutes: 1.7296660502751668,
      avg_loss: 0.11172064344088237,
      epsilon: 0.009995187929535779,
      vehicles: 325,
      completed_trips: 457,
      passenger_throughput: 7478.181818181819,
      memory_size: 40800,
    },
    {
      episode: 137,
      scenario: "Day 20250717, Cycle 1",
      reward: -373.61404821815177,
      steps: 300,
      time_minutes: 1.7347513914108277,
      avg_loss: 0.11679833114147187,
      epsilon: 0.009995187929535779,
      vehicles: 354,
      completed_trips: 494,
      passenger_throughput: 8083.636363636364,
      memory_size: 41100,
    },
    {
      episode: 138,
      scenario: "Day 20250703, Cycle 1",
      reward: -373.54246650257676,
      steps: 300,
      time_minutes: 1.7539085308710733,
      avg_loss: 0.11388347374896209,
      epsilon: 0.009995187929535779,
      vehicles: 370,
      completed_trips: 498,
      passenger_throughput: 8149.09090909091,
      memory_size: 41400,
    },
    {
      episode: 139,
      scenario: "Day 20250717, Cycle 1",
      reward: -318.81788808530985,
      steps: 300,
      time_minutes: 1.7462263782819112,
      avg_loss: 0.11613067055741946,
      epsilon: 0.009995187929535779,
      vehicles: 350,
      completed_trips: 495,
      passenger_throughput: 8100.000000000001,
      memory_size: 41700,
    },
    {
      episode: 140,
      scenario: "Day 20250815, Cycle 1",
      reward: -359.12668207255183,
      steps: 300,
      time_minutes: 1.7527400612831117,
      avg_loss: 0.11787037315467994,
      epsilon: 0.009995187929535779,
      vehicles: 357,
      completed_trips: 486,
      passenger_throughput: 7952.727272727273,
      memory_size: 42000,
    },
    {
      episode: 141,
      scenario: "Day 20250805, Cycle 1",
      reward: -270.2889090816757,
      steps: 300,
      time_minutes: 1.769753348827362,
      avg_loss: 0.11742714484532674,
      epsilon: 0.009995187929535779,
      vehicles: 360,
      completed_trips: 510,
      passenger_throughput: 8345.454545454546,
      memory_size: 42300,
    },
    {
      episode: 142,
      scenario: "Day 20250717, Cycle 1",
      reward: -291.8686813953919,
      steps: 300,
      time_minutes: 1.7824541926383972,
      avg_loss: 0.11934503979980945,
      epsilon: 0.009995187929535779,
      vehicles: 348,
      completed_trips: 489,
      passenger_throughput: 8001.818181818182,
      memory_size: 42600,
    },
    {
      episode: 143,
      scenario: "Day 20250717, Cycle 1",
      reward: -391.5542250598351,
      steps: 300,
      time_minutes: 1.7890559832255046,
      avg_loss: 0.1201256288588047,
      epsilon: 0.009995187929535779,
      vehicles: 372,
      completed_trips: 471,
      passenger_throughput: 7707.272727272728,
      memory_size: 42900,
    },
    {
      episode: 144,
      scenario: "Day 20250704, Cycle 3",
      reward: -313.6237514142179,
      steps: 300,
      time_minutes: 1.7992317398389182,
      avg_loss: 0.11597508065402508,
      epsilon: 0.009995187929535779,
      vehicles: 379,
      completed_trips: 501,
      passenger_throughput: 8198.181818181818,
      memory_size: 43200,
    },
    {
      episode: 145,
      scenario: "Day 20250703, Cycle 1",
      reward: -402.5364144287686,
      steps: 300,
      time_minutes: 1.8006608764330545,
      avg_loss: 0.1166962103297313,
      epsilon: 0.009995187929535779,
      vehicles: 363,
      completed_trips: 495,
      passenger_throughput: 8100.000000000001,
      memory_size: 43500,
    },
    {
      episode: 146,
      scenario: "Day 20250812, Cycle 1",
      reward: -361.1042009032001,
      steps: 300,
      time_minutes: 1.8026897271474203,
      avg_loss: 0.11380026951432227,
      epsilon: 0.009995187929535779,
      vehicles: 367,
      completed_trips: 512,
      passenger_throughput: 8378.181818181818,
      memory_size: 43800,
    },
    {
      episode: 147,
      scenario: "Day 20250716, Cycle 1",
      reward: -323.33048182097707,
      steps: 300,
      time_minutes: 1.7962747017542522,
      avg_loss: 0.11785000761349997,
      epsilon: 0.009995187929535779,
      vehicles: 347,
      completed_trips: 497,
      passenger_throughput: 8132.727272727273,
      memory_size: 44100,
    },
    {
      episode: 148,
      scenario: "Day 20250701, Cycle 1",
      reward: -367.56416841082387,
      steps: 300,
      time_minutes: 1.7850287834803262,
      avg_loss: 0.1155633203436931,
      epsilon: 0.009995187929535779,
      vehicles: 376,
      completed_trips: 515,
      passenger_throughput: 8427.272727272728,
      memory_size: 44400,
    },
    {
      episode: 149,
      scenario: "Day 20250704, Cycle 3",
      reward: -341.82204147394356,
      steps: 300,
      time_minutes: 1.7823162158330281,
      avg_loss: 0.11277380129943292,
      epsilon: 0.009995187929535779,
      vehicles: 372,
      completed_trips: 505,
      passenger_throughput: 8263.636363636364,
      memory_size: 44700,
    },
    {
      episode: 150,
      scenario: "Day 20250811, Cycle 3",
      reward: -377.42256239239424,
      steps: 300,
      time_minutes: 1.7766132513682047,
      avg_loss: 0.10953122665484746,
      epsilon: 0.009995187929535779,
      vehicles: 362,
      completed_trips: 471,
      passenger_throughput: 7707.272727272728,
      memory_size: 45000,
    },
    {
      episode: 151,
      scenario: "Day 20250815, Cycle 1",
      reward: -364.0684214824142,
      steps: 300,
      time_minutes: 1.7839053312937418,
      avg_loss: 0.1128538116812706,
      epsilon: 0.009995187929535779,
      vehicles: 357,
      completed_trips: 495,
      passenger_throughput: 8100.000000000001,
      memory_size: 45300,
    },
    {
      episode: 152,
      scenario: "Day 20250709, Cycle 1",
      reward: -342.8775737661814,
      steps: 300,
      time_minutes: 1.7792975227038066,
      avg_loss: 0.11639047138392926,
      epsilon: 0.009995187929535779,
      vehicles: 324,
      completed_trips: 466,
      passenger_throughput: 7625.454545454546,
      memory_size: 45600,
    },
    {
      episode: 153,
      scenario: "Day 20250703, Cycle 3",
      reward: -300.7950264264064,
      steps: 300,
      time_minutes: 1.789161197344462,
      avg_loss: 0.11478063213328521,
      epsilon: 0.009995187929535779,
      vehicles: 353,
      completed_trips: 502,
      passenger_throughput: 8214.545454545456,
      memory_size: 45900,
    },
    {
      episode: 154,
      scenario: "Day 20250707, Cycle 1",
      reward: -339.202195567107,
      steps: 300,
      time_minutes: 1.779405403137207,
      avg_loss: 0.11201627105474472,
      epsilon: 0.009995187929535779,
      vehicles: 346,
      completed_trips: 488,
      passenger_throughput: 7985.454545454546,
      memory_size: 46200,
    },
    {
      episode: 155,
      scenario: "Day 20250707, Cycle 1",
      reward: -354.00020222141814,
      steps: 300,
      time_minutes: 1.7930567145347596,
      avg_loss: 0.10960957679897547,
      epsilon: 0.009995187929535779,
      vehicles: 355,
      completed_trips: 482,
      passenger_throughput: 7887.272727272728,
      memory_size: 46500,
    },
    {
      episode: 156,
      scenario: "Day 20250717, Cycle 1",
      reward: -323.2385202701013,
      steps: 300,
      time_minutes: 1.7925397197405497,
      avg_loss: 0.11181485176086425,
      epsilon: 0.009995187929535779,
      vehicles: 348,
      completed_trips: 497,
      passenger_throughput: 8132.727272727273,
      memory_size: 46800,
    },
    {
      episode: 157,
      scenario: "Day 20250812, Cycle 2",
      reward: -331.72593686938933,
      steps: 300,
      time_minutes: 1.7851075053215026,
      avg_loss: 0.10910924224803845,
      epsilon: 0.009995187929535779,
      vehicles: 315,
      completed_trips: 479,
      passenger_throughput: 7838.181818181819,
      memory_size: 47100,
    },
    {
      episode: 158,
      scenario: "Day 20250812, Cycle 3",
      reward: -369.96619999848815,
      steps: 300,
      time_minutes: 1.7964930216471353,
      avg_loss: 0.10879723019897938,
      epsilon: 0.009995187929535779,
      vehicles: 351,
      completed_trips: 504,
      passenger_throughput: 8247.272727272728,
      memory_size: 47400,
    },
    {
      episode: 159,
      scenario: "Day 20250811, Cycle 3",
      reward: -348.1559122315183,
      steps: 300,
      time_minutes: 1.7985537727673848,
      avg_loss: 0.11253319102029005,
      epsilon: 0.009995187929535779,
      vehicles: 349,
      completed_trips: 488,
      passenger_throughput: 7985.454545454546,
      memory_size: 47700,
    },
    {
      episode: 160,
      scenario: "Day 20250703, Cycle 1",
      reward: -364.5155606400115,
      steps: 300,
      time_minutes: 1.8068991422653198,
      avg_loss: 0.11018266778439284,
      epsilon: 0.009995187929535779,
      vehicles: 367,
      completed_trips: 495,
      passenger_throughput: 8100.000000000001,
      memory_size: 48000,
    },
    {
      episode: 161,
      scenario: "Day 20250703, Cycle 1",
      reward: -401.73472441692417,
      steps: 300,
      time_minutes: 1.8052080194155375,
      avg_loss: 0.1018733966226379,
      epsilon: 0.009995187929535779,
      vehicles: 367,
      completed_trips: 498,
      passenger_throughput: 8149.09090909091,
      memory_size: 48300,
    },
    {
      episode: 162,
      scenario: "Day 20250818, Cycle 2",
      reward: -353.3011619724568,
      steps: 300,
      time_minutes: 1.8008798400561015,
      avg_loss: 0.10355057504028081,
      epsilon: 0.009995187929535779,
      vehicles: 339,
      completed_trips: 469,
      passenger_throughput: 7674.545454545455,
      memory_size: 48600,
    },
    {
      episode: 163,
      scenario: "Day 20250701, Cycle 1",
      reward: -355.2115376615233,
      steps: 300,
      time_minutes: 1.8165397882461547,
      avg_loss: 0.10371490340679884,
      epsilon: 0.009995187929535779,
      vehicles: 375,
      completed_trips: 511,
      passenger_throughput: 8361.818181818182,
      memory_size: 48900,
    },
    {
      episode: 164,
      scenario: "Day 20250805, Cycle 2",
      reward: -348.31194081155405,
      steps: 300,
      time_minutes: 1.811305324236552,
      avg_loss: 0.10362680816402038,
      epsilon: 0.009995187929535779,
      vehicles: 361,
      completed_trips: 500,
      passenger_throughput: 8181.818181818182,
      memory_size: 49200,
    },
    {
      episode: 165,
      scenario: "Day 20250717, Cycle 3",
      reward: -228.68698967642584,
      steps: 300,
      time_minutes: 1.819398864110311,
      avg_loss: 0.10237755986551443,
      epsilon: 0.009995187929535779,
      vehicles: 350,
      completed_trips: 512,
      passenger_throughput: 8378.181818181818,
      memory_size: 49500,
    },
    {
      episode: 166,
      scenario: "Day 20250703, Cycle 2",
      reward: -313.7720385471202,
      steps: 300,
      time_minutes: 1.8177763978640238,
      avg_loss: 0.10403777830302716,
      epsilon: 0.009995187929535779,
      vehicles: 370,
      completed_trips: 474,
      passenger_throughput: 7756.363636363637,
      memory_size: 49800,
    },
    {
      episode: 167,
      scenario: "Day 20250807, Cycle 3",
      reward: -359.92653947820367,
      steps: 300,
      time_minutes: 1.8104525804519653,
      avg_loss: 0.10240140145023664,
      epsilon: 0.009995187929535779,
      vehicles: 352,
      completed_trips: 468,
      passenger_throughput: 7658.181818181819,
      memory_size: 50000,
    },
    {
      episode: 168,
      scenario: "Day 20250812, Cycle 3",
      reward: -348.4445485893224,
      steps: 300,
      time_minutes: 1.8222378373146058,
      avg_loss: 0.10709802721937497,
      epsilon: 0.009995187929535779,
      vehicles: 360,
      completed_trips: 520,
      passenger_throughput: 8509.09090909091,
      memory_size: 50000,
    },
    {
      episode: 169,
      scenario: "Day 20250821, Cycle 3",
      reward: -285.73445483369716,
      steps: 300,
      time_minutes: 1.8239494641621907,
      avg_loss: 0.10507491807142894,
      epsilon: 0.009995187929535779,
      vehicles: 350,
      completed_trips: 486,
      passenger_throughput: 7952.727272727273,
      memory_size: 50000,
    },
    {
      episode: 170,
      scenario: "Day 20250703, Cycle 2",
      reward: -311.0017753096185,
      steps: 300,
      time_minutes: 1.860952627658844,
      avg_loss: 0.10764855782190959,
      epsilon: 0.009995187929535779,
      vehicles: 370,
      completed_trips: 521,
      passenger_throughput: 8525.454545454546,
      memory_size: 50000,
    },
    {
      episode: 171,
      scenario: "Day 20250805, Cycle 1",
      reward: -373.30717629964624,
      steps: 300,
      time_minutes: 1.8361770987510682,
      avg_loss: 0.10157869637012482,
      epsilon: 0.009995187929535779,
      vehicles: 368,
      completed_trips: 484,
      passenger_throughput: 7920.000000000001,
      memory_size: 50000,
    },
    {
      episode: 172,
      scenario: "Day 20250708, Cycle 1",
      reward: -373.55840743746154,
      steps: 300,
      time_minutes: 1.8132555882136028,
      avg_loss: 0.10020495822032292,
      epsilon: 0.009995187929535779,
      vehicles: 316,
      completed_trips: 473,
      passenger_throughput: 7740.000000000001,
      memory_size: 50000,
    },
    {
      episode: 173,
      scenario: "Day 20250715, Cycle 3",
      reward: -281.0350709898393,
      steps: 300,
      time_minutes: 1.808036780357361,
      avg_loss: 0.10763504662861427,
      epsilon: 0.009995187929535779,
      vehicles: 339,
      completed_trips: 465,
      passenger_throughput: 7609.09090909091,
      memory_size: 50000,
    },
    {
      episode: 174,
      scenario: "Day 20250811, Cycle 2",
      reward: -370.5193818833673,
      steps: 300,
      time_minutes: 1.8208825230598449,
      avg_loss: 0.10856526408344508,
      epsilon: 0.009995187929535779,
      vehicles: 351,
      completed_trips: 485,
      passenger_throughput: 7936.363636363637,
      memory_size: 50000,
    },
    {
      episode: 175,
      scenario: "Day 20250812, Cycle 3",
      reward: -367.0495461539939,
      steps: 300,
      time_minutes: 1.8279017686843873,
      avg_loss: 0.11356657770772775,
      epsilon: 0.009995187929535779,
      vehicles: 366,
      completed_trips: 521,
      passenger_throughput: 8525.454545454546,
      memory_size: 50000,
    },
    {
      episode: 176,
      scenario: "Day 20250709, Cycle 1",
      reward: -375.8280336557043,
      steps: 300,
      time_minutes: 1.8179854234059651,
      avg_loss: 0.10983310372879108,
      epsilon: 0.009995187929535779,
      vehicles: 324,
      completed_trips: 470,
      passenger_throughput: 7690.909090909092,
      memory_size: 50000,
    },
    {
      episode: 177,
      scenario: "Day 20250704, Cycle 3",
      reward: -380.67255051865413,
      steps: 300,
      time_minutes: 1.8368528922398886,
      avg_loss: 0.10878269515931606,
      epsilon: 0.009995187929535779,
      vehicles: 371,
      completed_trips: 498,
      passenger_throughput: 8149.09090909091,
      memory_size: 50000,
    },
    {
      episode: 178,
      scenario: "Day 20250819, Cycle 3",
      reward: -368.48891631646325,
      steps: 300,
      time_minutes: 1.8269725561141967,
      avg_loss: 0.11250099373360475,
      epsilon: 0.009995187929535779,
      vehicles: 311,
      completed_trips: 473,
      passenger_throughput: 7740.000000000001,
      memory_size: 50000,
    },
    {
      episode: 179,
      scenario: "Day 20250708, Cycle 2",
      reward: -325.3631249688698,
      steps: 300,
      time_minutes: 1.8236156066258749,
      avg_loss: 0.11775785346825918,
      epsilon: 0.009995187929535779,
      vehicles: 311,
      completed_trips: 454,
      passenger_throughput: 7429.09090909091,
      memory_size: 50000,
    },
    {
      episode: 180,
      scenario: "Day 20250821, Cycle 2",
      reward: -366.0092936554742,
      steps: 300,
      time_minutes: 1.832095201810201,
      avg_loss: 0.11648581622789303,
      epsilon: 0.009995187929535779,
      vehicles: 332,
      completed_trips: 470,
      passenger_throughput: 7690.909090909092,
      memory_size: 50000,
    },
    {
      episode: 181,
      scenario: "Day 20250704, Cycle 3",
      reward: -392.6781146022952,
      steps: 300,
      time_minutes: 1.8440317352612814,
      avg_loss: 0.1216927221417427,
      epsilon: 0.009995187929535779,
      vehicles: 375,
      completed_trips: 499,
      passenger_throughput: 8165.454545454546,
      memory_size: 50000,
    },
    {
      episode: 182,
      scenario: "Day 20250717, Cycle 1",
      reward: -286.33096643839696,
      steps: 300,
      time_minutes: 1.8391642014185587,
      avg_loss: 0.12035745104153951,
      epsilon: 0.009995187929535779,
      vehicles: 347,
      completed_trips: 485,
      passenger_throughput: 7936.363636363637,
      memory_size: 50000,
    },
    {
      episode: 183,
      scenario: "Day 20250708, Cycle 1",
      reward: -349.3778752120153,
      steps: 300,
      time_minutes: 1.839833645025889,
      avg_loss: 0.11642397758861382,
      epsilon: 0.009995187929535779,
      vehicles: 304,
      completed_trips: 478,
      passenger_throughput: 7821.818181818182,
      memory_size: 50000,
    },
    {
      episode: 184,
      scenario: "Day 20250821, Cycle 1",
      reward: -308.956158258034,
      steps: 300,
      time_minutes: 1.8528687874476115,
      avg_loss: 0.1149182258049647,
      epsilon: 0.009995187929535779,
      vehicles: 340,
      completed_trips: 503,
      passenger_throughput: 8230.909090909092,
      memory_size: 50000,
    },
    {
      episode: 185,
      scenario: "Day 20250715, Cycle 2",
      reward: -303.4630657856053,
      steps: 300,
      time_minutes: 1.8475167632102967,
      avg_loss: 0.11059515029191971,
      epsilon: 0.009995187929535779,
      vehicles: 313,
      completed_trips: 460,
      passenger_throughput: 7527.272727272728,
      memory_size: 50000,
    },
    {
      episode: 186,
      scenario: "Day 20250703, Cycle 3",
      reward: -349.2601178502686,
      steps: 300,
      time_minutes: 1.854962154229482,
      avg_loss: 0.10882632634292046,
      epsilon: 0.009995187929535779,
      vehicles: 355,
      completed_trips: 505,
      passenger_throughput: 8263.636363636364,
      memory_size: 50000,
    },
    {
      episode: 187,
      scenario: "Day 20250811, Cycle 1",
      reward: -344.738538900434,
      steps: 300,
      time_minutes: 1.8508793155352274,
      avg_loss: 0.1075772316629688,
      epsilon: 0.009995187929535779,
      vehicles: 322,
      completed_trips: 497,
      passenger_throughput: 8132.727272727273,
      memory_size: 50000,
    },
    {
      episode: 188,
      scenario: "Day 20250805, Cycle 1",
      reward: -367.01127691088715,
      steps: 300,
      time_minutes: 1.8648466110229491,
      avg_loss: 0.10885572007546822,
      epsilon: 0.009995187929535779,
      vehicles: 355,
      completed_trips: 490,
      passenger_throughput: 8018.181818181819,
      memory_size: 50000,
    },
    {
      episode: 189,
      scenario: "Day 20250708, Cycle 1",
      reward: -354.15738999404635,
      steps: 300,
      time_minutes: 1.8462099154790244,
      avg_loss: 0.10618269219994544,
      epsilon: 0.009995187929535779,
      vehicles: 313,
      completed_trips: 482,
      passenger_throughput: 7887.272727272728,
      memory_size: 50000,
    },
    {
      episode: 190,
      scenario: "Day 20250812, Cycle 2",
      reward: -331.0734997093,
      steps: 300,
      time_minutes: 1.8505131721496582,
      avg_loss: 0.10159689209113519,
      epsilon: 0.009995187929535779,
      vehicles: 319,
      completed_trips: 469,
      passenger_throughput: 7674.545454545455,
      memory_size: 50000,
    },
    {
      episode: 191,
      scenario: "Day 20250807, Cycle 3",
      reward: -337.1608812628208,
      steps: 300,
      time_minutes: 1.855591396490733,
      avg_loss: 0.09707928645114104,
      epsilon: 0.009995187929535779,
      vehicles: 343,
      completed_trips: 486,
      passenger_throughput: 7952.727272727273,
      memory_size: 50000,
    },
    {
      episode: 192,
      scenario: "Day 20250807, Cycle 3",
      reward: -297.22482708958916,
      steps: 300,
      time_minutes: 1.8533507148424784,
      avg_loss: 0.10040672719478608,
      epsilon: 0.009995187929535779,
      vehicles: 352,
      completed_trips: 479,
      passenger_throughput: 7838.181818181819,
      memory_size: 50000,
    },
    {
      episode: 193,
      scenario: "Day 20250812, Cycle 3",
      reward: -337.2368865974915,
      steps: 300,
      time_minutes: 1.8701100587844848,
      avg_loss: 0.10006363186985254,
      epsilon: 0.009995187929535779,
      vehicles: 373,
      completed_trips: 495,
      passenger_throughput: 8100.000000000001,
      memory_size: 50000,
    },
    {
      episode: 194,
      scenario: "Day 20250815, Cycle 1",
      reward: -293.0989416373202,
      steps: 300,
      time_minutes: 1.8672317862510681,
      avg_loss: 0.09936421749492487,
      epsilon: 0.009995187929535779,
      vehicles: 369,
      completed_trips: 483,
      passenger_throughput: 7903.636363636364,
      memory_size: 50000,
    },
    {
      episode: 195,
      scenario: "Day 20250812, Cycle 1",
      reward: -367.08290105322476,
      steps: 300,
      time_minutes: 1.8706026236216227,
      avg_loss: 0.10192166873564323,
      epsilon: 0.009995187929535779,
      vehicles: 370,
      completed_trips: 509,
      passenger_throughput: 8329.09090909091,
      memory_size: 50000,
    },
    {
      episode: 196,
      scenario: "Day 20250703, Cycle 2",
      reward: -292.0198498173936,
      steps: 300,
      time_minutes: 1.88120938539505,
      avg_loss: 0.10067832181851069,
      epsilon: 0.009995187929535779,
      vehicles: 350,
      completed_trips: 534,
      passenger_throughput: 8738.181818181818,
      memory_size: 50000,
    },
    {
      episode: 197,
      scenario: "Day 20250804, Cycle 1",
      reward: -295.05606739772566,
      steps: 300,
      time_minutes: 1.9153676827748616,
      avg_loss: 0.10019347459077835,
      epsilon: 0.009995187929535779,
      vehicles: 340,
      completed_trips: 472,
      passenger_throughput: 7723.636363636364,
      memory_size: 50000,
    },
    {
      episode: 198,
      scenario: "Day 20250821, Cycle 2",
      reward: -344.3950934566274,
      steps: 300,
      time_minutes: 1.8604406118392944,
      avg_loss: 0.09729658549030622,
      epsilon: 0.009995187929535779,
      vehicles: 327,
      completed_trips: 460,
      passenger_throughput: 7527.272727272728,
      memory_size: 50000,
    },
    {
      episode: 199,
      scenario: "Day 20250715, Cycle 1",
      reward: -367.56768404409536,
      steps: 300,
      time_minutes: 1.8859611670176188,
      avg_loss: 0.0964416452869773,
      epsilon: 0.009995187929535779,
      vehicles: 399,
      completed_trips: 502,
      passenger_throughput: 8214.545454545456,
      memory_size: 50000,
    },
    {
      episode: 200,
      scenario: "Day 20250717, Cycle 3",
      reward: -271.22105516869016,
      steps: 300,
      time_minutes: 1.8743066867192586,
      avg_loss: 0.09274251428743203,
      epsilon: 0.009995187929535779,
      vehicles: 354,
      completed_trips: 517,
      passenger_throughput: 8460.0,
      memory_size: 50000,
    },
    {
      episode: 201,
      scenario: "Day 20250811, Cycle 2",
      reward: -373.5531680209208,
      steps: 300,
      time_minutes: 1.8794849673906961,
      avg_loss: 0.09699916064739228,
      epsilon: 0.009995187929535779,
      vehicles: 360,
      completed_trips: 481,
      passenger_throughput: 7870.909090909092,
      memory_size: 50000,
    },
    {
      episode: 202,
      scenario: "Day 20250807, Cycle 2",
      reward: -378.87752665972044,
      steps: 300,
      time_minutes: 1.9331344723701478,
      avg_loss: 0.09602105682094891,
      epsilon: 0.009995187929535779,
      vehicles: 365,
      completed_trips: 486,
      passenger_throughput: 7952.727272727273,
      memory_size: 50000,
    },
    {
      episode: 203,
      scenario: "Day 20250819, Cycle 3",
      reward: -295.02067111787477,
      steps: 300,
      time_minutes: 1.9251538475354513,
      avg_loss: 0.09356056900074085,
      epsilon: 0.009995187929535779,
      vehicles: 327,
      completed_trips: 475,
      passenger_throughput: 7772.727272727273,
      memory_size: 50000,
    },
    {
      episode: 204,
      scenario: "Day 20250707, Cycle 3",
      reward: -321.88141682640276,
      steps: 300,
      time_minutes: 2.002540345986684,
      avg_loss: 0.09764171638836464,
      epsilon: 0.009995187929535779,
      vehicles: 300,
      completed_trips: 468,
      passenger_throughput: 7658.181818181819,
      memory_size: 50000,
    },
    {
      episode: 205,
      scenario: "Day 20250703, Cycle 1",
      reward: -339.1305776871672,
      steps: 300,
      time_minutes: 1.8911553025245667,
      avg_loss: 0.09490571158627668,
      epsilon: 0.009995187929535779,
      vehicles: 364,
      completed_trips: 516,
      passenger_throughput: 8443.636363636364,
      memory_size: 50000,
    },
    {
      episode: 206,
      scenario: "Day 20250804, Cycle 2",
      reward: -366.6612587071527,
      steps: 300,
      time_minutes: 1.958677339553833,
      avg_loss: 0.09082231901586056,
      epsilon: 0.009995187929535779,
      vehicles: 358,
      completed_trips: 478,
      passenger_throughput: 7821.818181818182,
      memory_size: 50000,
    },
    {
      episode: 207,
      scenario: "Day 20250709, Cycle 3",
      reward: -280.142306394947,
      steps: 300,
      time_minutes: 1.8970842321713766,
      avg_loss: 0.08857233641048272,
      epsilon: 0.009995187929535779,
      vehicles: 303,
      completed_trips: 476,
      passenger_throughput: 7789.09090909091,
      memory_size: 50000,
    },
    {
      episode: 208,
      scenario: "Day 20250804, Cycle 1",
      reward: -381.08657084324494,
      steps: 300,
      time_minutes: 1.9463630239168803,
      avg_loss: 0.08801867047945658,
      epsilon: 0.009995187929535779,
      vehicles: 347,
      completed_trips: 478,
      passenger_throughput: 7821.818181818182,
      memory_size: 50000,
    },
    {
      episode: 209,
      scenario: "Day 20250812, Cycle 3",
      reward: -385.52021706912166,
      steps: 300,
      time_minutes: 1.9271361311276753,
      avg_loss: 0.0878319393719236,
      epsilon: 0.009995187929535779,
      vehicles: 362,
      completed_trips: 511,
      passenger_throughput: 8361.818181818182,
      memory_size: 50000,
    },
    {
      episode: 210,
      scenario: "Day 20250811, Cycle 2",
      reward: -275.5684076458881,
      steps: 300,
      time_minutes: 1.919870408376058,
      avg_loss: 0.08738233972340823,
      epsilon: 0.009995187929535779,
      vehicles: 361,
      completed_trips: 466,
      passenger_throughput: 7625.454545454546,
      memory_size: 50000,
    },
    {
      episode: 211,
      scenario: "Day 20250821, Cycle 1",
      reward: -318.86732495918085,
      steps: 300,
      time_minutes: 1.9484293381373088,
      avg_loss: 0.09437208766738574,
      epsilon: 0.009995187929535779,
      vehicles: 334,
      completed_trips: 508,
      passenger_throughput: 8312.727272727274,
      memory_size: 50000,
    },
    {
      episode: 212,
      scenario: "Day 20250709, Cycle 3",
      reward: -366.87725731854795,
      steps: 300,
      time_minutes: 1.9462100982666015,
      avg_loss: 0.09314555602769058,
      epsilon: 0.009995187929535779,
      vehicles: 322,
      completed_trips: 462,
      passenger_throughput: 7560.000000000001,
      memory_size: 50000,
    },
    {
      episode: 213,
      scenario: "Day 20250715, Cycle 3",
      reward: -248.41837690117632,
      steps: 300,
      time_minutes: 1.933475959300995,
      avg_loss: 0.09434013484666745,
      epsilon: 0.009995187929535779,
      vehicles: 334,
      completed_trips: 472,
      passenger_throughput: 7723.636363636364,
      memory_size: 50000,
    },
    {
      episode: 214,
      scenario: "Day 20250717, Cycle 2",
      reward: -299.68470043459183,
      steps: 300,
      time_minutes: 1.9175722082455953,
      avg_loss: 0.09330935494353373,
      epsilon: 0.009995187929535779,
      vehicles: 357,
      completed_trips: 505,
      passenger_throughput: 8263.636363636364,
      memory_size: 50000,
    },
    {
      episode: 215,
      scenario: "Day 20250704, Cycle 1",
      reward: -289.6090078389228,
      steps: 300,
      time_minutes: 1.9168715596199035,
      avg_loss: 0.08874532752980789,
      epsilon: 0.009995187929535779,
      vehicles: 342,
      completed_trips: 513,
      passenger_throughput: 8394.545454545456,
      memory_size: 50000,
    },
    {
      episode: 216,
      scenario: "Day 20250804, Cycle 1",
      reward: -344.37690506766745,
      steps: 300,
      time_minutes: 1.9169586261113485,
      avg_loss: 0.0854450743024548,
      epsilon: 0.009995187929535779,
      vehicles: 348,
      completed_trips: 476,
      passenger_throughput: 7789.09090909091,
      memory_size: 50000,
    },
    {
      episode: 217,
      scenario: "Day 20250703, Cycle 2",
      reward: -352.5145231960075,
      steps: 300,
      time_minutes: 1.9274562875429788,
      avg_loss: 0.08636137859274944,
      epsilon: 0.009995187929535779,
      vehicles: 378,
      completed_trips: 527,
      passenger_throughput: 8623.636363636364,
      memory_size: 50000,
    },
    {
      episode: 218,
      scenario: "Day 20250703, Cycle 2",
      reward: -347.3223024760281,
      steps: 300,
      time_minutes: 1.9257144729296367,
      avg_loss: 0.08712039155264696,
      epsilon: 0.009995187929535779,
      vehicles: 368,
      completed_trips: 517,
      passenger_throughput: 8460.0,
      memory_size: 50000,
    },
    {
      episode: 219,
      scenario: "Day 20250710, Cycle 2",
      reward: -296.21451586054985,
      steps: 300,
      time_minutes: 1.9069961627324423,
      avg_loss: 0.08731541201472283,
      epsilon: 0.009995187929535779,
      vehicles: 313,
      completed_trips: 464,
      passenger_throughput: 7592.727272727273,
      memory_size: 50000,
    },
    {
      episode: 220,
      scenario: "Day 20250819, Cycle 3",
      reward: -366.1988742352466,
      steps: 300,
      time_minutes: 1.911644164721171,
      avg_loss: 0.09017111954589685,
      epsilon: 0.009995187929535779,
      vehicles: 336,
      completed_trips: 466,
      passenger_throughput: 7625.454545454546,
      memory_size: 50000,
    },
    {
      episode: 221,
      scenario: "Day 20250709, Cycle 3",
      reward: -230.60879059431696,
      steps: 300,
      time_minutes: 1.903851052125295,
      avg_loss: 0.09879106527815262,
      epsilon: 0.009995187929535779,
      vehicles: 307,
      completed_trips: 476,
      passenger_throughput: 7789.09090909091,
      memory_size: 50000,
    },
    {
      episode: 222,
      scenario: "Day 20250821, Cycle 2",
      reward: -307.2690521689235,
      steps: 300,
      time_minutes: 1.9018827676773071,
      avg_loss: 0.0944842139010628,
      epsilon: 0.009995187929535779,
      vehicles: 333,
      completed_trips: 476,
      passenger_throughput: 7789.09090909091,
      memory_size: 50000,
    },
    {
      episode: 223,
      scenario: "Day 20250809, Cycle 2",
      reward: -375.07707507514095,
      steps: 300,
      time_minutes: 1.9143690824508668,
      avg_loss: 0.08932229576011498,
      epsilon: 0.009995187929535779,
      vehicles: 356,
      completed_trips: 487,
      passenger_throughput: 7969.09090909091,
      memory_size: 50000,
    },
    {
      episode: 224,
      scenario: "Day 20250716, Cycle 1",
      reward: -340.9609452812064,
      steps: 300,
      time_minutes: 1.9069929440816245,
      avg_loss: 0.0864531559497118,
      epsilon: 0.009995187929535779,
      vehicles: 349,
      completed_trips: 491,
      passenger_throughput: 8034.545454545455,
      memory_size: 50000,
    },
    {
      episode: 225,
      scenario: "Day 20250704, Cycle 3",
      reward: -393.8439123077762,
      steps: 300,
      time_minutes: 1.9231485287348429,
      avg_loss: 0.08686150630315145,
      epsilon: 0.009995187929535779,
      vehicles: 386,
      completed_trips: 487,
      passenger_throughput: 7969.09090909091,
      memory_size: 50000,
    },
    {
      episode: 226,
      scenario: "Day 20250809, Cycle 2",
      reward: -351.1004654697259,
      steps: 300,
      time_minutes: 1.913337560494741,
      avg_loss: 0.08571643956005573,
      epsilon: 0.009995187929535779,
      vehicles: 357,
      completed_trips: 511,
      passenger_throughput: 8361.818181818182,
      memory_size: 50000,
    },
    {
      episode: 227,
      scenario: "Day 20250811, Cycle 2",
      reward: -358.1271689198211,
      steps: 300,
      time_minutes: 1.917224939664205,
      avg_loss: 0.08469488182415565,
      epsilon: 0.009995187929535779,
      vehicles: 358,
      completed_trips: 480,
      passenger_throughput: 7854.545454545455,
      memory_size: 50000,
    },
    {
      episode: 228,
      scenario: "Day 20250710, Cycle 2",
      reward: -268.6694224386322,
      steps: 300,
      time_minutes: 1.9037444154421488,
      avg_loss: 0.08080539014190435,
      epsilon: 0.009995187929535779,
      vehicles: 318,
      completed_trips: 462,
      passenger_throughput: 7560.000000000001,
      memory_size: 50000,
    },
    {
      episode: 229,
      scenario: "Day 20250716, Cycle 1",
      reward: -392.03568793744586,
      steps: 300,
      time_minutes: 1.9225271781285604,
      avg_loss: 0.07651627109696468,
      epsilon: 0.009995187929535779,
      vehicles: 361,
      completed_trips: 489,
      passenger_throughput: 8001.818181818182,
      memory_size: 50000,
    },
    {
      episode: 230,
      scenario: "Day 20250707, Cycle 1",
      reward: -356.30520519284846,
      steps: 300,
      time_minutes: 1.9130417267481485,
      avg_loss: 0.07640374085555474,
      epsilon: 0.009995187929535779,
      vehicles: 342,
      completed_trips: 486,
      passenger_throughput: 7952.727272727273,
      memory_size: 50000,
    },
    {
      episode: 231,
      scenario: "Day 20250707, Cycle 1",
      reward: -374.64415488017244,
      steps: 300,
      time_minutes: 1.922109031677246,
      avg_loss: 0.07884832579642534,
      epsilon: 0.009995187929535779,
      vehicles: 345,
      completed_trips: 491,
      passenger_throughput: 8034.545454545455,
      memory_size: 50000,
    },
    {
      episode: 232,
      scenario: "Day 20250819, Cycle 3",
      reward: -329.0280497461809,
      steps: 300,
      time_minutes: 1.9081218560536704,
      avg_loss: 0.07582726457466682,
      epsilon: 0.009995187929535779,
      vehicles: 328,
      completed_trips: 479,
      passenger_throughput: 7838.181818181819,
      memory_size: 50000,
    },
    {
      episode: 233,
      scenario: "Day 20250704, Cycle 3",
      reward: -393.7004752358259,
      steps: 300,
      time_minutes: 1.9298691908518473,
      avg_loss: 0.07673130715886751,
      epsilon: 0.009995187929535779,
      vehicles: 377,
      completed_trips: 504,
      passenger_throughput: 8247.272727272728,
      memory_size: 50000,
    },
    {
      episode: 234,
      scenario: "Day 20250819, Cycle 2",
      reward: -260.5388810234406,
      steps: 300,
      time_minutes: 1.9111457268397014,
      avg_loss: 0.07509617697447539,
      epsilon: 0.009995187929535779,
      vehicles: 321,
      completed_trips: 478,
      passenger_throughput: 7821.818181818182,
      memory_size: 50000,
    },
    {
      episode: 235,
      scenario: "Day 20250805, Cycle 1",
      reward: -358.7878444725057,
      steps: 300,
      time_minutes: 1.9249692916870118,
      avg_loss: 0.07184818179657061,
      epsilon: 0.009995187929535779,
      vehicles: 368,
      completed_trips: 494,
      passenger_throughput: 8083.636363636364,
      memory_size: 50000,
    },
    {
      episode: 236,
      scenario: "Day 20250704, Cycle 3",
      reward: -337.6521936784257,
      steps: 300,
      time_minutes: 1.9263102054595946,
      avg_loss: 0.0764835845803221,
      epsilon: 0.009995187929535779,
      vehicles: 377,
      completed_trips: 498,
      passenger_throughput: 8149.09090909091,
      memory_size: 50000,
    },
    {
      episode: 237,
      scenario: "Day 20250716, Cycle 3",
      reward: -333.8502287325513,
      steps: 300,
      time_minutes: 1.9299535870552063,
      avg_loss: 0.07345615940789382,
      epsilon: 0.009995187929535779,
      vehicles: 363,
      completed_trips: 504,
      passenger_throughput: 8247.272727272728,
      memory_size: 50000,
    },
    {
      episode: 238,
      scenario: "Day 20250701, Cycle 1",
      reward: -395.8522776543478,
      steps: 300,
      time_minutes: 1.9343488653500875,
      avg_loss: 0.07319399408996105,
      epsilon: 0.009995187929535779,
      vehicles: 375,
      completed_trips: 511,
      passenger_throughput: 8361.818181818182,
      memory_size: 50000,
    },
    {
      episode: 239,
      scenario: "Day 20250811, Cycle 2",
      reward: -328.8414655474937,
      steps: 300,
      time_minutes: 1.9275437355041505,
      avg_loss: 0.06999397000918786,
      epsilon: 0.009995187929535779,
      vehicles: 360,
      completed_trips: 483,
      passenger_throughput: 7903.636363636364,
      memory_size: 50000,
    },
    {
      episode: 240,
      scenario: "Day 20250707, Cycle 3",
      reward: -348.53620974311934,
      steps: 300,
      time_minutes: 1.915709420045217,
      avg_loss: 0.0691223748276631,
      epsilon: 0.009995187929535779,
      vehicles: 302,
      completed_trips: 473,
      passenger_throughput: 7740.000000000001,
      memory_size: 50000,
    },
    {
      episode: 241,
      scenario: "Day 20250821, Cycle 2",
      reward: -324.6754195188619,
      steps: 300,
      time_minutes: 1.9175844589869182,
      avg_loss: 0.07281419118245443,
      epsilon: 0.009995187929535779,
      vehicles: 337,
      completed_trips: 473,
      passenger_throughput: 7740.000000000001,
      memory_size: 50000,
    },
    {
      episode: 242,
      scenario: "Day 20250809, Cycle 2",
      reward: -342.66109681385285,
      steps: 300,
      time_minutes: 1.932576870918274,
      avg_loss: 0.07147496799627939,
      epsilon: 0.009995187929535779,
      vehicles: 357,
      completed_trips: 488,
      passenger_throughput: 7985.454545454546,
      memory_size: 50000,
    },
    {
      episode: 243,
      scenario: "Day 20250812, Cycle 3",
      reward: -338.1997087705833,
      steps: 300,
      time_minutes: 1.947103989124298,
      avg_loss: 0.07157975220431884,
      epsilon: 0.009995187929535779,
      vehicles: 345,
      completed_trips: 506,
      passenger_throughput: 8280.0,
      memory_size: 50000,
    },
    {
      episode: 244,
      scenario: "Day 20250704, Cycle 1",
      reward: -351.71961377772567,
      steps: 300,
      time_minutes: 1.9378984570503235,
      avg_loss: 0.06946297895163298,
      epsilon: 0.009995187929535779,
      vehicles: 340,
      completed_trips: 491,
      passenger_throughput: 8034.545454545455,
      memory_size: 50000,
    },
    {
      episode: 245,
      scenario: "Day 20250807, Cycle 3",
      reward: -352.4244931784582,
      steps: 300,
      time_minutes: 1.938470987478892,
      avg_loss: 0.07262480585525433,
      epsilon: 0.009995187929535779,
      vehicles: 343,
      completed_trips: 475,
      passenger_throughput: 7772.727272727273,
      memory_size: 50000,
    },
    {
      episode: 246,
      scenario: "Day 20250819, Cycle 3",
      reward: -326.8341566456153,
      steps: 300,
      time_minutes: 1.9348600824673972,
      avg_loss: 0.07519597735255956,
      epsilon: 0.009995187929535779,
      vehicles: 330,
      completed_trips: 467,
      passenger_throughput: 7641.818181818182,
      memory_size: 50000,
    },
    {
      episode: 247,
      scenario: "Day 20250701, Cycle 1",
      reward: -379.07897812456605,
      steps: 300,
      time_minutes: 1.9470321893692017,
      avg_loss: 0.07262490833799044,
      epsilon: 0.009995187929535779,
      vehicles: 393,
      completed_trips: 526,
      passenger_throughput: 8607.272727272728,
      memory_size: 50000,
    },
    {
      episode: 248,
      scenario: "Day 20250811, Cycle 1",
      reward: -312.9897591386077,
      steps: 300,
      time_minutes: 1.9438719868659973,
      avg_loss: 0.07371416178842385,
      epsilon: 0.009995187929535779,
      vehicles: 332,
      completed_trips: 503,
      passenger_throughput: 8230.909090909092,
      memory_size: 50000,
    },
    {
      episode: 249,
      scenario: "Day 20250703, Cycle 3",
      reward: -324.144846848878,
      steps: 300,
      time_minutes: 1.9504347801208497,
      avg_loss: 0.06977105933551987,
      epsilon: 0.009995187929535779,
      vehicles: 347,
      completed_trips: 504,
      passenger_throughput: 8247.272727272728,
      memory_size: 50000,
    },
    {
      episode: 250,
      scenario: "Day 20250821, Cycle 1",
      reward: -376.4639082468435,
      steps: 300,
      time_minutes: 1.9429035464922586,
      avg_loss: 0.06876733537763358,
      epsilon: 0.009995187929535779,
      vehicles: 325,
      completed_trips: 502,
      passenger_throughput: 8214.545454545456,
      memory_size: 50000,
    },
    {
      episode: 251,
      scenario: "Day 20250709, Cycle 2",
      reward: -309.3172720994534,
      steps: 300,
      time_minutes: 1.9347965598106385,
      avg_loss: 0.06955748893320561,
      epsilon: 0.009995187929535779,
      vehicles: 328,
      completed_trips: 455,
      passenger_throughput: 7445.454545454546,
      memory_size: 50000,
    },
    {
      episode: 252,
      scenario: "Day 20250708, Cycle 1",
      reward: -347.0304791091143,
      steps: 300,
      time_minutes: 1.9332125504811606,
      avg_loss: 0.06684035557011764,
      epsilon: 0.009995187929535779,
      vehicles: 307,
      completed_trips: 487,
      passenger_throughput: 7969.09090909091,
      memory_size: 50000,
    },
    {
      episode: 253,
      scenario: "Day 20250821, Cycle 3",
      reward: -357.121369827938,
      steps: 300,
      time_minutes: 1.9517152508099873,
      avg_loss: 0.06728539040933053,
      epsilon: 0.009995187929535779,
      vehicles: 357,
      completed_trips: 464,
      passenger_throughput: 7592.727272727273,
      memory_size: 50000,
    },
    {
      episode: 254,
      scenario: "Day 20250717, Cycle 1",
      reward: -328.8922367691743,
      steps: 300,
      time_minutes: 1.9484602729479472,
      avg_loss: 0.06818561139206092,
      epsilon: 0.009995187929535779,
      vehicles: 360,
      completed_trips: 489,
      passenger_throughput: 8001.818181818182,
      memory_size: 50000,
    },
    {
      episode: 255,
      scenario: "Day 20250804, Cycle 1",
      reward: -330.5283502245258,
      steps: 300,
      time_minutes: 1.9465499560038249,
      avg_loss: 0.06979298379272222,
      epsilon: 0.009995187929535779,
      vehicles: 347,
      completed_trips: 474,
      passenger_throughput: 7756.363636363637,
      memory_size: 50000,
    },
    {
      episode: 256,
      scenario: "Day 20250707, Cycle 1",
      reward: -298.1496434563992,
      steps: 300,
      time_minutes: 1.954054594039917,
      avg_loss: 0.07132731337721149,
      epsilon: 0.009995187929535779,
      vehicles: 350,
      completed_trips: 483,
      passenger_throughput: 7903.636363636364,
      memory_size: 50000,
    },
    {
      episode: 257,
      scenario: "Day 20250807, Cycle 3",
      reward: -353.4325189103818,
      steps: 300,
      time_minutes: 1.9474599838256836,
      avg_loss: 0.0705271311601003,
      epsilon: 0.009995187929535779,
      vehicles: 354,
      completed_trips: 469,
      passenger_throughput: 7674.545454545455,
      memory_size: 50000,
    },
    {
      episode: 258,
      scenario: "Day 20250708, Cycle 2",
      reward: -312.74058347684877,
      steps: 300,
      time_minutes: 1.9448120713233947,
      avg_loss: 0.07020436377575,
      epsilon: 0.009995187929535779,
      vehicles: 298,
      completed_trips: 449,
      passenger_throughput: 7347.272727272728,
      memory_size: 50000,
    },
    {
      episode: 259,
      scenario: "Day 20250804, Cycle 2",
      reward: -342.1355487928917,
      steps: 300,
      time_minutes: 1.9618948658307394,
      avg_loss: 0.06958475838725765,
      epsilon: 0.009995187929535779,
      vehicles: 356,
      completed_trips: 479,
      passenger_throughput: 7838.181818181819,
      memory_size: 50000,
    },
    {
      episode: 260,
      scenario: "Day 20250715, Cycle 2",
      reward: -306.719511813972,
      steps: 300,
      time_minutes: 1.9539465665817262,
      avg_loss: 0.0678753683095177,
      epsilon: 0.009995187929535779,
      vehicles: 319,
      completed_trips: 462,
      passenger_throughput: 7560.000000000001,
      memory_size: 50000,
    },
    {
      episode: 261,
      scenario: "Day 20250703, Cycle 1",
      reward: -385.4055762937848,
      steps: 300,
      time_minutes: 1.9651040077209472,
      avg_loss: 0.0635445086658001,
      epsilon: 0.009995187929535779,
      vehicles: 363,
      completed_trips: 503,
      passenger_throughput: 8230.909090909092,
      memory_size: 50000,
    },
    {
      episode: 262,
      scenario: "Day 20250709, Cycle 3",
      reward: -306.6207153483971,
      steps: 300,
      time_minutes: 1.9500249783198038,
      avg_loss: 0.0647167979553342,
      epsilon: 0.009995187929535779,
      vehicles: 297,
      completed_trips: 481,
      passenger_throughput: 7870.909090909092,
      memory_size: 50000,
    },
    {
      episode: 263,
      scenario: "Day 20250807, Cycle 2",
      reward: -373.15250793301414,
      steps: 300,
      time_minutes: 1.9618778626124065,
      avg_loss: 0.06587568912655115,
      epsilon: 0.009995187929535779,
      vehicles: 366,
      completed_trips: 479,
      passenger_throughput: 7838.181818181819,
      memory_size: 50000,
    },
    {
      episode: 264,
      scenario: "Day 20250704, Cycle 3",
      reward: -373.5452479736633,
      steps: 300,
      time_minutes: 2.02152019739151,
      avg_loss: 0.06566184116527438,
      epsilon: 0.009995187929535779,
      vehicles: 371,
      completed_trips: 497,
      passenger_throughput: 8132.727272727273,
      memory_size: 50000,
    },
    {
      episode: 265,
      scenario: "Day 20250704, Cycle 1",
      reward: -339.78925071780975,
      steps: 300,
      time_minutes: 1.9595048626263936,
      avg_loss: 0.06888339723149936,
      epsilon: 0.009995187929535779,
      vehicles: 335,
      completed_trips: 495,
      passenger_throughput: 8100.000000000001,
      memory_size: 50000,
    },
    {
      episode: 266,
      scenario: "Day 20250716, Cycle 2",
      reward: -352.3702520672472,
      steps: 300,
      time_minutes: 1.9664195934931437,
      avg_loss: 0.06674474313855171,
      epsilon: 0.009995187929535779,
      vehicles: 344,
      completed_trips: 518,
      passenger_throughput: 8476.363636363638,
      memory_size: 50000,
    },
    {
      episode: 267,
      scenario: "Day 20250703, Cycle 2",
      reward: -300.8034294435751,
      steps: 300,
      time_minutes: 1.9711991866429648,
      avg_loss: 0.07020147533466418,
      epsilon: 0.009995187929535779,
      vehicles: 361,
      completed_trips: 536,
      passenger_throughput: 8770.909090909092,
      memory_size: 50000,
    },
    {
      episode: 268,
      scenario: "Day 20250812, Cycle 1",
      reward: -304.7772267145314,
      steps: 300,
      time_minutes: 1.9802855213483175,
      avg_loss: 0.06948747644200921,
      epsilon: 0.009995187929535779,
      vehicles: 366,
      completed_trips: 510,
      passenger_throughput: 8345.454545454546,
      memory_size: 50000,
    },
    {
      episode: 269,
      scenario: "Day 20250805, Cycle 1",
      reward: -380.5119065312483,
      steps: 300,
      time_minutes: 1.9774678548177083,
      avg_loss: 0.06678669673701128,
      epsilon: 0.009995187929535779,
      vehicles: 367,
      completed_trips: 496,
      passenger_throughput: 8116.363636363637,
      memory_size: 50000,
    },
    {
      episode: 270,
      scenario: "Day 20250710, Cycle 2",
      reward: -354.934177985812,
      steps: 300,
      time_minutes: 1.9658976435661315,
      avg_loss: 0.07013697038094202,
      epsilon: 0.009995187929535779,
      vehicles: 320,
      completed_trips: 451,
      passenger_throughput: 7380.000000000001,
      memory_size: 50000,
    },
    {
      episode: 271,
      scenario: "Day 20250815, Cycle 3",
      reward: -359.5233211690738,
      steps: 300,
      time_minutes: 1.9610025842984518,
      avg_loss: 0.0703134552637736,
      epsilon: 0.009995187929535779,
      vehicles: 323,
      completed_trips: 460,
      passenger_throughput: 7527.272727272728,
      memory_size: 50000,
    },
    {
      episode: 272,
      scenario: "Day 20250818, Cycle 3",
      reward: -332.4177177267869,
      steps: 300,
      time_minutes: 1.9658813198407492,
      avg_loss: 0.07146649667372307,
      epsilon: 0.009995187929535779,
      vehicles: 323,
      completed_trips: 463,
      passenger_throughput: 7576.363636363637,
      memory_size: 50000,
    },
    {
      episode: 273,
      scenario: "Day 20250818, Cycle 2",
      reward: -359.4893373977203,
      steps: 300,
      time_minutes: 1.97040696144104,
      avg_loss: 0.07211062174290418,
      epsilon: 0.009995187929535779,
      vehicles: 336,
      completed_trips: 472,
      passenger_throughput: 7723.636363636364,
      memory_size: 50000,
    },
    {
      episode: 274,
      scenario: "Day 20250812, Cycle 3",
      reward: -370.46009571306763,
      steps: 300,
      time_minutes: 1.9765859484672545,
      avg_loss: 0.0714093544272085,
      epsilon: 0.009995187929535779,
      vehicles: 354,
      completed_trips: 507,
      passenger_throughput: 8296.363636363638,
      memory_size: 50000,
    },
    {
      episode: 275,
      scenario: "Day 20250717, Cycle 2",
      reward: -275.02808090203587,
      steps: 300,
      time_minutes: 1.9785621643066407,
      avg_loss: 0.06605045403043429,
      epsilon: 0.009995187929535779,
      vehicles: 366,
      completed_trips: 515,
      passenger_throughput: 8427.272727272728,
      memory_size: 50000,
    },
    {
      episode: 276,
      scenario: "Day 20250809, Cycle 3",
      reward: -394.0209661825994,
      steps: 300,
      time_minutes: 1.9806177417437236,
      avg_loss: 0.0653516573086381,
      epsilon: 0.009995187929535779,
      vehicles: 357,
      completed_trips: 475,
      passenger_throughput: 7772.727272727273,
      memory_size: 50000,
    },
    {
      episode: 277,
      scenario: "Day 20250821, Cycle 2",
      reward: -338.38628057102494,
      steps: 300,
      time_minutes: 1.9746827721595763,
      avg_loss: 0.0641872799396515,
      epsilon: 0.009995187929535779,
      vehicles: 346,
      completed_trips: 469,
      passenger_throughput: 7674.545454545455,
      memory_size: 50000,
    },
    {
      episode: 278,
      scenario: "Day 20250709, Cycle 1",
      reward: -362.5193398109793,
      steps: 300,
      time_minutes: 1.9662249167760213,
      avg_loss: 0.06433320252845685,
      epsilon: 0.009995187929535779,
      vehicles: 316,
      completed_trips: 484,
      passenger_throughput: 7920.000000000001,
      memory_size: 50000,
    },
    {
      episode: 279,
      scenario: "Day 20250716, Cycle 1",
      reward: -376.5995918925558,
      steps: 300,
      time_minutes: 1.9773854573567708,
      avg_loss: 0.06747040839244922,
      epsilon: 0.009995187929535779,
      vehicles: 342,
      completed_trips: 508,
      passenger_throughput: 8312.727272727274,
      memory_size: 50000,
    },
    {
      episode: 280,
      scenario: "Day 20250715, Cycle 3",
      reward: -296.1223000871362,
      steps: 300,
      time_minutes: 1.976276163260142,
      avg_loss: 0.06488957577695449,
      epsilon: 0.009995187929535779,
      vehicles: 337,
      completed_trips: 470,
      passenger_throughput: 7690.909090909092,
      memory_size: 50000,
    },
    {
      episode: 281,
      scenario: "Day 20250715, Cycle 1",
      reward: -367.9847151796973,
      steps: 300,
      time_minutes: 2.0062626123428347,
      avg_loss: 0.06698990343759458,
      epsilon: 0.009995187929535779,
      vehicles: 406,
      completed_trips: 514,
      passenger_throughput: 8410.909090909092,
      memory_size: 50000,
    },
    {
      episode: 282,
      scenario: "Day 20250811, Cycle 3",
      reward: -358.3603892695428,
      steps: 300,
      time_minutes: 1.9878323634465536,
      avg_loss: 0.06395261359090607,
      epsilon: 0.009995187929535779,
      vehicles: 359,
      completed_trips: 481,
      passenger_throughput: 7870.909090909092,
      memory_size: 50000,
    },
    {
      episode: 283,
      scenario: "Day 20250707, Cycle 3",
      reward: -359.21417585896035,
      steps: 300,
      time_minutes: 1.9715964913368225,
      avg_loss: 0.06540499379858375,
      epsilon: 0.009995187929535779,
      vehicles: 304,
      completed_trips: 482,
      passenger_throughput: 7887.272727272728,
      memory_size: 50000,
    },
    {
      episode: 284,
      scenario: "Day 20250717, Cycle 3",
      reward: -310.03311584477024,
      steps: 300,
      time_minutes: 2.000549304485321,
      avg_loss: 0.06374768070876598,
      epsilon: 0.009995187929535779,
      vehicles: 362,
      completed_trips: 508,
      passenger_throughput: 8312.727272727274,
      memory_size: 50000,
    },
    {
      episode: 285,
      scenario: "Day 20250819, Cycle 2",
      reward: -270.803623747599,
      steps: 300,
      time_minutes: 1.982396121819814,
      avg_loss: 0.06575083817665775,
      epsilon: 0.009995187929535779,
      vehicles: 323,
      completed_trips: 476,
      passenger_throughput: 7789.09090909091,
      memory_size: 50000,
    },
    {
      episode: 286,
      scenario: "Day 20250811, Cycle 2",
      reward: -344.39678411096196,
      steps: 300,
      time_minutes: 1.9980555216471354,
      avg_loss: 0.06492799208809932,
      epsilon: 0.009995187929535779,
      vehicles: 361,
      completed_trips: 483,
      passenger_throughput: 7903.636363636364,
      memory_size: 50000,
    },
    {
      episode: 287,
      scenario: "Day 20250805, Cycle 2",
      reward: -362.90790454659884,
      steps: 300,
      time_minutes: 2.0082841078440348,
      avg_loss: 0.06468705415104826,
      epsilon: 0.009995187929535779,
      vehicles: 373,
      completed_trips: 501,
      passenger_throughput: 8198.181818181818,
      memory_size: 50000,
    },
    {
      episode: 288,
      scenario: "Day 20250716, Cycle 3",
      reward: -335.9880751463479,
      steps: 300,
      time_minutes: 2.001122800509135,
      avg_loss: 0.0644162212125957,
      epsilon: 0.009995187929535779,
      vehicles: 357,
      completed_trips: 512,
      passenger_throughput: 8378.181818181818,
      memory_size: 50000,
    },
    {
      episode: 289,
      scenario: "Day 20250809, Cycle 2",
      reward: -354.0969312892202,
      steps: 300,
      time_minutes: 2.0493253668149314,
      avg_loss: 0.06445533654342095,
      epsilon: 0.009995187929535779,
      vehicles: 355,
      completed_trips: 493,
      passenger_throughput: 8067.272727272728,
      memory_size: 50000,
    },
    {
      episode: 290,
      scenario: "Day 20250812, Cycle 2",
      reward: -260.7319142835976,
      steps: 300,
      time_minutes: 1.9814134001731873,
      avg_loss: 0.0691549874159197,
      epsilon: 0.009995187929535779,
      vehicles: 308,
      completed_trips: 483,
      passenger_throughput: 7903.636363636364,
      memory_size: 50000,
    },
    {
      episode: 291,
      scenario: "Day 20250707, Cycle 3",
      reward: -279.7501342423176,
      steps: 300,
      time_minutes: 1.9873685876528422,
      avg_loss: 0.0668656493537128,
      epsilon: 0.009995187929535779,
      vehicles: 307,
      completed_trips: 463,
      passenger_throughput: 7576.363636363637,
      memory_size: 50000,
    },
    {
      episode: 292,
      scenario: "Day 20250703, Cycle 2",
      reward: -331.87196106916207,
      steps: 300,
      time_minutes: 2.01366673707962,
      avg_loss: 0.06534498843674859,
      epsilon: 0.009995187929535779,
      vehicles: 358,
      completed_trips: 536,
      passenger_throughput: 8770.909090909092,
      memory_size: 50000,
    },
    {
      episode: 293,
      scenario: "Day 20250704, Cycle 3",
      reward: -403.12581349233085,
      steps: 300,
      time_minutes: 2.0179888884226482,
      avg_loss: 0.06681644640862942,
      epsilon: 0.009995187929535779,
      vehicles: 383,
      completed_trips: 496,
      passenger_throughput: 8116.363636363637,
      memory_size: 50000,
    },
    {
      episode: 294,
      scenario: "Day 20250717, Cycle 2",
      reward: -269.2577889565217,
      steps: 300,
      time_minutes: 1.999148190021515,
      avg_loss: 0.07062497417752941,
      epsilon: 0.009995187929535779,
      vehicles: 352,
      completed_trips: 514,
      passenger_throughput: 8410.909090909092,
      memory_size: 50000,
    },
    {
      episode: 295,
      scenario: "Day 20250709, Cycle 1",
      reward: -360.1309998249065,
      steps: 300,
      time_minutes: 1.9937958439191183,
      avg_loss: 0.06865779476861159,
      epsilon: 0.009995187929535779,
      vehicles: 325,
      completed_trips: 463,
      passenger_throughput: 7576.363636363637,
      memory_size: 50000,
    },
    {
      episode: 296,
      scenario: "Day 20250704, Cycle 1",
      reward: -400.57536965603464,
      steps: 300,
      time_minutes: 2.009164583683014,
      avg_loss: 0.06818036501606306,
      epsilon: 0.009995187929535779,
      vehicles: 354,
      completed_trips: 474,
      passenger_throughput: 7756.363636363637,
      memory_size: 50000,
    },
    {
      episode: 297,
      scenario: "Day 20250701, Cycle 1",
      reward: -339.3596692687246,
      steps: 300,
      time_minutes: 2.028938591480255,
      avg_loss: 0.0675704913213849,
      epsilon: 0.009995187929535779,
      vehicles: 384,
      completed_trips: 516,
      passenger_throughput: 8443.636363636364,
      memory_size: 50000,
    },
    {
      episode: 298,
      scenario: "Day 20250709, Cycle 3",
      reward: -280.1336372944101,
      steps: 300,
      time_minutes: 1.9961405158042909,
      avg_loss: 0.06706335694839557,
      epsilon: 0.009995187929535779,
      vehicles: 313,
      completed_trips: 463,
      passenger_throughput: 7576.363636363637,
      memory_size: 50000,
    },
    {
      episode: 299,
      scenario: "Day 20250815, Cycle 3",
      reward: -330.9956205633984,
      steps: 300,
      time_minutes: 1.996916361649831,
      avg_loss: 0.06875868772466977,
      epsilon: 0.009995187929535779,
      vehicles: 311,
      completed_trips: 482,
      passenger_throughput: 7887.272727272728,
      memory_size: 50000,
    },
    {
      episode: 300,
      scenario: "Day 20250821, Cycle 1",
      reward: -242.49132854500294,
      steps: 300,
      time_minutes: 2.004241669178009,
      avg_loss: 0.064629076551646,
      epsilon: 0.009995187929535779,
      vehicles: 322,
      completed_trips: 513,
      passenger_throughput: 8394.545454545456,
      memory_size: 50000,
    },
  ],
  validation_results: [
    {
      episode: 15,
      avg_reward: -353.5357533804029,
      reward_std: 35.49567721054235,
      avg_vehicles: 349.0,
      avg_completed_trips: 485.6,
      avg_passenger_throughput: 7946.181818181818,
      scenarios_tested: 10,
    },
    {
      episode: 30,
      avg_reward: -347.6860085322836,
      reward_std: 22.510078414472968,
      avg_vehicles: 352.0,
      avg_completed_trips: 478.3,
      avg_passenger_throughput: 7826.727272727274,
      scenarios_tested: 10,
    },
    {
      episode: 45,
      avg_reward: -357.38754481070816,
      reward_std: 32.313826665665076,
      avg_vehicles: 353.0,
      avg_completed_trips: 479.7,
      avg_passenger_throughput: 7849.636363636365,
      scenarios_tested: 10,
    },
    {
      episode: 60,
      avg_reward: -336.43264969472966,
      reward_std: 42.57783755719763,
      avg_vehicles: 352.7,
      avg_completed_trips: 480.7,
      avg_passenger_throughput: 7866.0,
      scenarios_tested: 10,
    },
    {
      episode: 75,
      avg_reward: -359.37977505509383,
      reward_std: 26.749437832779947,
      avg_vehicles: 351.7,
      avg_completed_trips: 482.2,
      avg_passenger_throughput: 7890.545454545454,
      scenarios_tested: 10,
    },
    {
      episode: 90,
      avg_reward: -364.5577619084572,
      reward_std: 35.95521729999587,
      avg_vehicles: 356.0,
      avg_completed_trips: 476.0,
      avg_passenger_throughput: 7789.090909090909,
      scenarios_tested: 10,
    },
    {
      episode: 105,
      avg_reward: -360.1486974435862,
      reward_std: 26.020960569283098,
      avg_vehicles: 354.2,
      avg_completed_trips: 480.7,
      avg_passenger_throughput: 7866.0,
      scenarios_tested: 10,
    },
    {
      episode: 120,
      avg_reward: -358.2474809811664,
      reward_std: 35.406866260596296,
      avg_vehicles: 353.2,
      avg_completed_trips: 477.1,
      avg_passenger_throughput: 7807.09090909091,
      scenarios_tested: 10,
    },
    {
      episode: 135,
      avg_reward: -354.31458488570803,
      reward_std: 16.968898381946236,
      avg_vehicles: 353.3,
      avg_completed_trips: 481.0,
      avg_passenger_throughput: 7870.909090909093,
      scenarios_tested: 10,
    },
    {
      episode: 150,
      avg_reward: -336.1710143333774,
      reward_std: 31.41103359200051,
      avg_vehicles: 352.4,
      avg_completed_trips: 480.3,
      avg_passenger_throughput: 7859.454545454546,
      scenarios_tested: 10,
    },
    {
      episode: 165,
      avg_reward: -353.09284778833614,
      reward_std: 37.73441751695552,
      avg_vehicles: 351.8,
      avg_completed_trips: 485.4,
      avg_passenger_throughput: 7942.909090909091,
      scenarios_tested: 10,
    },
    {
      episode: 180,
      avg_reward: -359.0879388207182,
      reward_std: 25.115224658235014,
      avg_vehicles: 353.0,
      avg_completed_trips: 478.9,
      avg_passenger_throughput: 7836.545454545454,
      scenarios_tested: 10,
    },
    {
      episode: 195,
      avg_reward: -367.00078887463314,
      reward_std: 28.06691093272975,
      avg_vehicles: 355.9,
      avg_completed_trips: 481.8,
      avg_passenger_throughput: 7884.0,
      scenarios_tested: 10,
    },
    {
      episode: 210,
      avg_reward: -353.6503765769641,
      reward_std: 26.498452070572775,
      avg_vehicles: 350.9,
      avg_completed_trips: 481.6,
      avg_passenger_throughput: 7880.727272727272,
      scenarios_tested: 10,
    },
    {
      episode: 225,
      avg_reward: -371.98168959426664,
      reward_std: 118.54853276460604,
      avg_vehicles: 355.1,
      avg_completed_trips: 479.3,
      avg_passenger_throughput: 7843.090909090909,
      scenarios_tested: 10,
    },
    {
      episode: 240,
      avg_reward: -361.34726119315746,
      reward_std: 28.79901953766755,
      avg_vehicles: 352.1,
      avg_completed_trips: 479.5,
      avg_passenger_throughput: 7846.363636363637,
      scenarios_tested: 10,
    },
    {
      episode: 255,
      avg_reward: -343.7492474179871,
      reward_std: 45.923761163952804,
      avg_vehicles: 354.5,
      avg_completed_trips: 476.9,
      avg_passenger_throughput: 7803.818181818182,
      scenarios_tested: 10,
    },
    {
      episode: 270,
      avg_reward: -353.8160076895788,
      reward_std: 29.284416433756018,
      avg_vehicles: 353.8,
      avg_completed_trips: 480.7,
      avg_passenger_throughput: 7866.000000000002,
      scenarios_tested: 10,
    },
    {
      episode: 285,
      avg_reward: -366.7972886272861,
      reward_std: 27.278435442863607,
      avg_vehicles: 353.5,
      avg_completed_trips: 479.3,
      avg_passenger_throughput: 7843.090909090909,
      scenarios_tested: 10,
    },
    {
      episode: 300,
      avg_reward: -358.49500821537436,
      reward_std: 24.434087483024125,
      avg_vehicles: 354.3,
      avg_completed_trips: 479.7,
      avg_passenger_throughput: 7849.636363636363,
      scenarios_tested: 10,
    },
  ],
  final_evaluation: {
    test_scenarios: 7,
    comparison_results: null,
    evaluation_timestamp: "2025-10-11T08:54:21.687312",
  },
  logger_summary: {
    experiment_id: "final_defense_training_350ep",
    session_id: "f50c8c75-b836-4b28-8b2b-847e7382822d",
    timestamp: "2025-10-11T08:54:21.690305",
    total_episodes: 50,
    performance_metrics: {
      avg_reward: -1.118983652608858,
      best_reward: -0.8083044284833429,
      reward_improvement: 4.742337903199193,
      avg_passenger_throughput: 7970.072727272728,
      avg_vehicles_served: 487.06,
      avg_pt_throughput: 0.0,
    },
    learning_metrics: {
      convergence_episode: -1,
      stability_score: 0.8874593171706626,
      exploration_rate: 0.8994029960954593,
    },
    config: {
      log_interval: 30,
      buffer_size: 100,
      total_steps: 14950,
    },
  },
  defense_ready: true,
  timestamp: "2025-10-11T08:54:21.691302",
} as const;
